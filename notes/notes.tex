 \documentclass[10pt,a4paper]{article}
\usepackage[margin=3cm]{geometry}
\usepackage{microtype}
\usepackage[shortlabels]{enumitem}
\usepackage{booktabs}
\usepackage[font=small,margin=0.1\linewidth]{caption}
\usepackage{graphicx,xcolor}
\usepackage[colorlinks=true,hyperindex=true]{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}

% New colors match the figures
\definecolor{newdarkblue}{RGB}{24,64,184}
\definecolor{newgreen}{RGB}{80,170,55}
\hypersetup{
    colorlinks,%
    citecolor=newdarkblue,%
    filecolor=red,%
    linkcolor=newdarkblue,%
    urlcolor=newgreen,%
    pdfnewwindow=true,%
    pdfstartview={FitH}
}

\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{mathtools}
\usepackage{esint}
\usepackage{braket}
\usepackage{subcaption} % for side by side plots
\usepackage{float} % trying to force figure placement
\usepackage{caption}

\numberwithin{equation}{section}

% Theorem-like environments

\newtheorem{theorem}{Theorem}[section]
    \newtheorem{proposition}[theorem]{Proposition}
    \newtheorem{lemma}[theorem]{Lemma}
    \newtheorem{corollary}[theorem]{Corollary}
    \newtheorem{exercise}[theorem]{Exercise}

\theoremstyle{definition}
    \newtheorem{definition}[theorem]{Definition}
    \newtheorem{remark}[theorem]{Remark}
    \newtheorem{example}[theorem]{Example}

\newcommand{\nb}[1]{{\color{teal} Nick: #1}}

% sets and measures
\def\err{{\overline{\mathbb R}}}
\def\rr{{\mathbb R}}
\def\zz{{\mathbb Z}}
\def\nn{{\mathbb N}}
\def\EE{{\mathbb E}}
\def\FF{{\mathbb F}}
\def\fu{{\mathfrak{u}}}
\def\ee{{\mathbb E}}
\def\cA{{\cal A}}
\def\cB{{\cal B}}
\def\cC{{\cal C}}
\def\cF{{\cal F}}
\def\cL{{\cal L}}
\def\cP{{\cal P}}
\def\P{{\mathbb P}}
\def\Q{{\mathbb Q}}
\def\Sym{{\mathbb S}}
% entropies
\newcommand{\ip}[1]{\langle#1\rangle}
\newcommand{\Sc}{h_{\textnormal{c}}}
\newcommand{\Sr}{h_{\textnormal{r}}}
\newcommand{\htop}{h_{\textnormal{top}}}
\newcommand{\ptop}{p_{\textnormal{top}}}

% differential operator from Beccari, Claudio. TUGboat, Volume 18 (1997), No. 1
	% the complicated stuff is just for spacing
	\makeatletter
	\providecommand*{\diff}%
	{\@ifnextchar^{\DIfF}{\DIfF^{}}}
	\def\DIfF^#1{%
	\mathop{\mathrm{\mathstrut d}}%
	\nolimits^{#1}\gobblespace}
	\def\gobblespace{%
	\futurelet\diffarg\opspace}
	\def\opspace{%
	\let\DiffSpace\!%
	\ifx\diffarg(%
	\let\DiffSpace\relax
	\else
	\ifx\diffarg%
	\let\DiffSpace\relax
	\else
	\ifx\diffarg\{%
	\let\DiffSpace\relax
	\fi\fi\fi\DiffSpace}

\newcommand{\dd}{\diff}
\newcommand{\xtrue}{\ensuremath{x^\natural}}
\newcommand{\Exp}[1]{\mathrm{e}^{#1}}
\renewcommand{\complement}{\mathsf{c}}
\DeclarePairedDelimiterX{\norm}[1]{\lVert}{\rVert}{#1}
\DeclareMathOperator{\logsumexp}{logsumexp}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\aff}{aff}
\DeclareMathOperator{\cl}{cl}
\DeclareMathOperator{\rint}{rint}
\DeclareMathOperator{\logexp}{logexp}
\DeclareMathOperator{\softmax}{softmax}
\DeclareMathOperator{\vecmax}{vecmax}
\DeclareMathOperator{\argmax}{argmax}
\DeclareMathOperator{\interior}{int}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\per}{per}
\newcommand{\fin}{{\mathrm{fin}}}
\newcommand{\shift}{T}
\newcommand{\invar}{_{\textnormal{inv}}}
\newcommand{\un}{^{\textnormal{uni}}}
\DeclareMathOperator{\epi}{epi}
\DeclareMathOperator{\dist}{dist}
\DeclareMathOperator{\LimOut}{LimOut}
\DeclareMathOperator{\LimInn}{LimInn}
\DeclareMathOperator{\argmin}{argmin}
\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\KL}{KL}
\DeclareMathOperator{\spann}{span}

\linespread{1.2}

\def\uuline#1{\underline{\underline{#1}}}

\usepackage{authblk}
\title{Dual methods for entropy-regularized\\moment-constrained optimization}
\author[1]{Nicholas Barnfield}
\affil[1]{Department of Statistics, Harvard University, Cambridge, MA, USA}
\author[2]{Michael P. Friedlander}
\affil[2]{Departments of Computer Science and Mathematics, University of British Columbia, Vancouver, BC, Canada}
\author[3]{Tim Hoheisel}
\affil[3]{Department of Mathematics, McGill University, Montreal, QC, Canada}
\date{\today}

\begin{document}

\maketitle

\textbf{Color scheme:}
\begin{itemize}
    \item \textcolor{blue}{Things to be added.}
    \item \textcolor{red}{Things to be verified/sorted out (otherwise likely incorrect).}
    \item \textcolor{teal}{Small comments that can be removed.}
    
\end{itemize}

\tableofcontents

\section{Introduction}
Let $(\Omega, \mu)$ be a finite measure space, where $\mu$ is a finite measure defined on subsets of the underlying set $\Omega$.
% MPF: Ok to use $(\Omega, \cF, \mu)$ if we also say what is $\cF$.
Suppose that an unknown nonnegative density $\xtrue\in L_1( \Omega, \mu)$ is observed through $m$ discrete samples
\begin{equation}\label{eq:moments-2}
    b_i:=\int_\Omega \xtrue(\omega) a_i(\omega) \,d\mu(\omega) \qquad (i=1,\dots,m),
\end{equation}
 that reveal the moment of $\xtrue$ with respect to a known collection of test functions $\{a_1, \dots, a_m\} \subset L_\infty(\Omega, \mu)$. The task is to approximate $\xtrue$ by solving the constrained relative-entropy optimization problem
\begin{equation}\label{eq:Primal}
    \min_{x\ge0} \Set{ H(x \mid q) | \int_\Omega x(\omega)a_i(\omega)\,d\mu(\omega) = b_i \quad (i=1,\dots,m) },
\end{equation}
where the relative entropy $H(x \mid q)$ of a candidate density $x\in L_1( \Omega, \mu)$ with respect to a prior density $q\in L_1( \Omega, \mu)$ is defined as
\begin{equation*}
    H(x \mid q) := \int_\Omega x(\omega) \log \frac{x(\omega)}{q(\omega)} \,d\mu(\omega).
\end{equation*}
We assume throughout that the measures induced by $x$ and $q$ are absolutely continuous with respect to the base measure $\mu$.

In this paper we describe a set of algorithms for obtaining maximum-entropy solutions to the moment-constrained optimization problem~\eqref{eq:Primal}. Our aim is to provide a suite of algorithms, accompanied by efficient software implementations that achieve high-accuracy using scalable computational kernels.

We consider a relaxation of this problem that allows for error in matching the moment measurements. The reformulated problem introduces an explicit scaled residual term $y\in\rr^m$ to the moment constraints, and regularizes the relative entropy with a quadratic term. The resulting problem is
\begin{equation}\label{eq:Primal2}
    \tag{P$_\lambda$}
    \min\, \Set{ H(x \mid q) + \tfrac{\lambda}{2}\norm{y}^2 | (x,y)\in\cF_\lambda,\ x\ge0},
\end{equation}
where
\begin{equation}\label{eq:FeasibleSet}
    \cF_\lambda := \Set{ (x,y)\in L_1( \Omega, \mu)\times\rr^m | \int_\Omega x(\omega)a_i(\omega)\,d\mu(\omega) = b_i - \lambda y_i \quad (i=1,\dots,m) }
\end{equation}
is the set of moment constraints and the nonnegative regularization parameter $\lambda$ controls the degree to which these are enforced. Observe that $\lambda=0$ recovers the original problem~\eqref{eq:Primal}.

\subsection{Motivation}

As described in detail by Decarreau et al.~\cite{decarreau_DualMethodsEntropy_1992}, the dual problem to~\eqref{eq:Primal2} is unconstrained problem over $\rr^n$ with a differentiable objective. This dual problem then be solved by a variety of first- or second-order optimization methods. This approach has been leveraged in various contexts, including entropy-regularized optimal transport~\cite{cuturi_SemidualRegularizedOptimal_2018}, where the dual problem is solved by a limited-memory BFGS algorithm~\cite{liu_LimitedMemoryBFGS_1989}; by Eriksson~\cite{eriksson_NoteSolutionLarge_1980}, who solves the dual problem by a Newton method. 

As established by Ben Tal et al.~\cite{ben-tal_RoleDualityOptimization_1988} and Decarreau et al.~\cite{decarreau_DualMethodsEntropy_1992}, the dual of the regularized problem~\eqref{eq:Primal2} is given by the unconstrained finite-dimensional problem
\begin{equation}\label{eq:Dual}
    \max_{y\in\rr^m} \Set{ \ip{b,y} - \tfrac{\lambda}{2}\norm{y}^2 - \int_\Omega q(\omega)\exp\left(\sum_{i=1}^m y_i a_i(\omega)-1\right) \,d\mu(\omega) }.
\end{equation}
[Note -- we might rederive this result, because neither of these papers gives the precise dual for this problem. Also need to specify the required constraint qualification.] The unique primal-dual solution $(x_y, y)$ must satisfy the equations
\begin{subequations}
\begin{align}\label{eq:PrimalDualMap}
   (x_y, y) &\in \cF_\lambda\\ 
    x_y(\omega) &= q(\omega)\exp\left((A^*y)(\omega)-1\right) \quad \mbox{a.e.,}
\end{align}
\end{subequations}
where we denote $A^*y\in L_\infty(\Omega,\mu)$ as the function $(A^*y)(\omega) := \sum_{i=1}^m y_i a_i(\omega)$.

As has been observed by Decarreau et al.~\cite{decarreau_DualMethodsEntropy_1992} and Ben-Tal et al.~\cite{ben-tal_RoleDualityOptimization_1988}, and many others, the dual problem is smooth and can be solved efficiently by a variety of gradient-related methods. In the finite-dimensional setting, notable examples include Eriksson~\cite{eriksson_NoteSolutionLarge_1980}, who solves the dual problem by a Newton method, and Cuturi and Peyr\'e~\cite{cuturi_SemidualRegularizedOptimal_2018} in the context of optimal transport, who recommend the limited-memory BFGS~\cite{liu_LimitedMemoryBFGS_1989} algorithm.

A significant concern with this dual formulation, however, is the numerical stability of computations with its gradient and Hessian. In particular, the exponential function can easily overflow or underflow during intermediate computations of an algorithm, even if the final solution is well scaled. Cuturi and Peyr\'e~\cite{cuturi_SemidualRegularizedOptimal_2018} suggest moving the computations into the log domain to avoid numerical issues. In Newton methods, however, require the actual values of the Hessian, not their logarithms. Moreover, the dual objective gradient is not Lipschitz continuous, which can lead to slow convergence of first-order methods, though there has been recent work on developing first-order methods for this setting that match the convergence rates for smooth objectives~\cite{luAcceleratedFirstorderMethods2023,malitskyAdaptiveGradientDescent2020}.

\subsection{Applications}

\subsubsection{Spectral density estimation}

Describe the physics spectral density estimation problem in high-energy physics. Describe this as a variation of the moment problem. 

After the discretization, the setting is $\Omega = \{1, \dots, n\}$ (or any finite set of $n$ elements) and $\mu$ is the counting measure on $\Omega$, i.e. $\mu(\{\omega\}) = 1$ $\forall \omega \in \Omega$. Therefore,
\[
\int_\Omega x(\omega)a_i(\omega)\,d\mu(\omega) = \sum_{\omega = 1}^n x(\omega) a_i(\omega) = [Ax]_i
\]
for $A \in \rr^{m \times n}$ with entries $A_{i, \omega}$ and $x = [x(1) \cdots x(n)]^T \in \rr^{n}$. Also,
\[
 H(x \mid q) = \sum_{\omega = 1}^n x(\omega) \log \frac{x(\omega)}{q(\omega)}.
\]


\subsubsection{Hausdorff moment problem}

When $\Omega\subset[0,1]$ and the basis function $a_i$ in~\eqref{eq:moments-2} are the monomials $a_i(\omega)=\omega^{i-1}$, problem~\eqref{eq:Primal} is known as the Hausdorff moment problem. Describe variations, including fractional moments~\cite{gzyl_HausdorffMomentProblem_2010}. Borwein and Lewis~\cite{borwein_ConvergenceBestEntropy_1991} describe how the maximum entropy solution converges as the number of measurements $m$ increases.

\subsubsection{Entropy regularized linear programming}

Our approach allows for the solution of entropy-regularized linear programs, as follows. 
Let $c\in L_\infty(\Omega,\mu)$. Observe that the entropy-regularized linear program
\begin{equation}\label{eq:semi-inf-lp}
    \min_{x\ge0} \Set{ \ip{c,x} + \epsilon \int_\Omega x(\omega) \log x(\omega) \,d\mu(\omega) | \int_\Omega x(\omega)a_i(\omega)\,d\mu(\omega) = b_i \quad (i=1,\dots,m) }.
\end{equation}
fits into the relative-entropy framework of~\eqref{eq:Primal} with $q:=\exp(-c/\epsilon)$.

\nb{Rather than taking $c\in L_\infty(\Omega,\mu)$ and $x \in  L_1(\Omega,\mu)$, we can instead take  $x, c \in L_2(\Omega,\mu)$. To be precise, should we be writing $\argmin$ since \eqref{eq:semi-inf-lp} differs by a factor of $\epsilon$.}

\section{Approaches}

The central feature of our approach is to imposition of a level-set constraint on the primal variable $x$. Specifically,, the constraint $(x,y)\in\cF_\lambda$ in the primal problem~\eqref{eq:Primal2} is replaced by the restricted constraint
\begin{equation}\label{eq:level-set}
    (x,y)\in \cF_{t,\lambda}:=\cF_\lambda \cap (t\Delta\times\rr^m),
\end{equation}
where $$t\Delta:=\set{x\in L_1( \Omega, \mu) | x\ge0, \int_\Omega x(\omega)\,d\mu(\omega)=t}$$ is the $t$-scaled simplex. This modification yields a compact feasible set for the primal problem, which in turn results in a dual objective that possesses a Lipschitz-continuous gradient, as demonstrated below. The structure induced by this constraint ensures that the dual problem is well-scaled and thus amenable to efficient numerical optimization by various methods. Of course, the additional level-set constraint necessitates the determination of an additional scaling parameters $t$ to identify the optimal value $t^\natural$ for which $x^\natural\in t^\natural\Delta$. However, this added complexity is offset by the favorable scaling properties of the problem, which facilitate the derivation of error bounds. These bounds are pivotal in the construction of a level-set method, where progress is achieved through a sequence of increasingly tight affine approximations.


We consider two approaches. The first is a global method that applies Newton's method on the value function, using lower minorants derived from dual solution. The second is a local method that applies Newton's method to an augmented system.

\subsection{Global: Value function iterations}

Define the primal and dual objective functions $\phi_p: L_1(\Omega,\mu)\times\rr_+\to\err$ and $\phi_d:\rr^m\times\rr_+\to\rr$ as 
\begin{subequations}\label{eq:primal-dual-objectives}
\begin{align}\label{eq:primal-objective}
    \phi_p(x,t) &= H(x \mid q) + \tfrac{\lambda}{2}\norm{y}^2 + \delta(x,y\mid \cF_{t,\lambda})\\
    \phi_d(y,t) &= \ip{b,y} - \tfrac{\lambda}{2}\norm{y}^2 - t\int_\Omega q(\omega)\exp\left((A^*y)(\omega)\right) \,d\mu(\omega) + t\log t,
\end{align}
\end{subequations}

The following proposition establishes the connection between the primal and dual objectives, 
\begin{proposition}\label{prop:strong-duality-attainment}
  For all $(x,y)\in L_1(\Omega,\mu)\times\rr^m$, $\lambda>0$
  \begin{equation}
    \phi_p(x,t) \ge \phi_d(y,t) \quad (\forall t>0),
  \end{equation}
  where equality holds if and only if $(x,y)=(x_t,y_t)$  where
  \begin{align}\label{eq:primal-dual-maps}
    x_t &:= tq\exp(A^*y_t)/\int_\Omega q\exp(A^*y_t)(\omega)\,d\mu(\omega)\quad\text{a.e.},\\
    y_t &:= \frac1\lambda
    \left[
      b_i - \int_\Omega x(\omega)a_i(\omega)\,d\mu(\omega)
    \right]_{i=1}^m.
  \end{align}
\end{proposition}
\begin{proof}
The proof is standard in the literature, but there are probably best to lay out the proof given that there are lots of details~\cite{ben-tal_RoleDualityOptimization_1988, decarreau_DualMethodsEntropy_1992}. Use the identity
\[
  tH(x/t\mid q/t) = H(x\mid q) \quad (\forall t>0).
\]
\end{proof}

\subsubsection{Lower minorants via duality}

Define the dual objective
\begin{equation}\label{eq:dual-value}
    \phi_d:(y,t)\in\rr^m\times\rr_+\mapsto {\ip{b,y} - \tfrac{\lambda}{2}\norm{y}^2 - t\int_\Omega q(\omega)\exp\left((A^*y)(\omega)\right) \,d\mu(\omega) + t\log t}.
\end{equation}

Our goal is now to determine a sequence of values $t_k$ such that $P(t_k)$ converges to the optimal value of~\eqref{eq:Primal2} as $k\to\infty$. We will use the dual solution to construct lower minorants of $P(t)$, which we use as part of a Newton step to update $t_k$.  The benefit of this approach is that the scaled simplex $t\Delta$, when incorporated into the objective function, leads to a well-scaled dual problem.Observe that
\begin{align*}
 P(t) &= \min\Set{tH(x/t\mid q/t) + \delta_{t\Delta}(x)+ \tfrac{\lambda}{2}\norm{y}^2 | (x, y) \in \cF}\\
      &= \max\Set{\ip{b,y} - \tfrac{\lambda}{2}\norm{y}^2 - t\log\int_\Omega \tfrac1t q(\omega)\exp\left((A^*y)(\omega)\right) \,d\mu(\omega) | y\in\rr^m},
\end{align*}
which we obtain via the Fenchel conjugate
\[
    (tH(\cdot/t\mid q/t) + \delta_{t\Delta})^* = t\log\int_\Omega q(\omega)\exp\left((A^*y)(\omega)\right) \,d\mu(\omega).
\]
The second equality requires a constraint qualification, such as the Slater condition given by Decarreau et al.~\cite[Lemma~2.6]{decarreau_DualMethodsEntropy_1992}.

The dual objective, after rearranging terms involving $t$, is
\[
  D(y,t) := \ip{b,y} - \tfrac{\lambda}{2}\norm{y}^2 - t\log\int_\Omega q(\omega)\exp\left((A^*y)(\omega)\right) \,d\mu(\omega) + t\log t,
\]
which verifies the convexity of $D$ in $t$.

Consider a vector $\bar y$ provides a lower minorant of $P$ at $\bar t$. In particular, for all $t$,
\begin{align}
P(t) &\ge D(y,t)\\
     &= D(\bar y, \bar t) + D(\bar y, t) - D(\bar y, \bar t)
     \ge \bar P(t),
\end{align}
where
\begin{equation}\label{eq:minorant}
    \bar P(t) := D(\bar y, \bar t) + s(t-\bar t)
\end{equation}
is an affine function of $t$ with slope
$$s = D'(\bar y, \cdot)(\bar t) = \log t + 1 - \log\int_\Omega q(\omega)\exp((A^*\bar y)(\omega))\,d\mu(\omega).$$

\subsubsection{Inexact Newton's method}

The method we described is based on applying an inexact Newton method to the nonlinear equation
\begin{equation}\label{eq:Newton-equation}
    P(t) = \sigma,
\end{equation}
where the parameter $\sigma$ is an upper bound on the optimal value of~\eqref{eq:Primal2}. \marginpar{Discuss how to choose $\sigma$.} We apply a variant of the inexact Newton method described by Aravkin et al.~\cite[Section~2.2]{aravkin_LevelsetMethodsConvex_2019}, which requires a sufficiently tight affine minorant oracle, as formalized here.

\begin{definition}\label{def:minorant-oracle}
    An sufficiently tight affine minorant oracle for $P$ at $\bar t\in[\alpha, \beta]$ is a function
    \begin{equation}
        \bar t \mapsto \ell + s(t - \bar t)
    \end{equation}
    that minorizes $P$ and $P()$

    \begin{equation}\label{eq:minorant-oracle}
        P(t) \ge \bar P(t) \quad \text{and} \quad P(t) = \bar P(t) \quad \text{if and only if} \quad t = \bar t.
    \end{equation}
\end{definition}

\begin{itemize}
    \item apply the level-set method of Aravkin et al.~\cite{aravkinLevelsetMethodsConvex2019}
    \item the level-set method guarantees that we can recover $\bar t$ such that $P(\bar t)\le\sigma + \epsilon$
    \item method provides well-defined inexact optimality requirements for dual evaluation
    \item how to choose $\sigma$? One possibility: $$\sigma = \lambda\bar\sigma + \int_\Omega q(\omega)\log q(\omega)\,d\mu(\omega),$$
    where $\bar\sigma$ is the variance of the measurements $b_i$
\end{itemize}

\subsection{Local: Newton's method}

Describe Newton's method on the $m+1$ nonlinear equations
$$
F(y,t) = \begin{bmatrix}
    \nabla_y D(y,t)\\
    \nabla_t D(y,t)
\end{bmatrix} = 0
$$

\begin{itemize}
    \item This method is already implemented in the Julia code. Works great as long as we have a good starting point $(y,t)$
    \item Idea: run the level-set method with loose convergence tolerance, then warm start the local method.
\end{itemize}


\section{Primal and dual problems}

Let $\mu \in \rint \Delta_n$\footnote{The assumption that $\mu$ has full support can be removed by optimizing over $\rr^M$ where $M:= |\{j: \mu_j \neq 0\}|$ since $\KL(x|\mu) = \infty$ whenever $\supp x \nsubseteq \supp \mu$ (when $\exists j$ such that $x_j = 0$ and $\mu_j \neq 0$). This is discussed more in the remark below.} (i.e. $\mu \in \rr^n_{++}$ and $e^T\mu = 1$), $A \in \rr^{m \times n}$, and $b \in \rr^m$. In view of the practical applications of the work herein, we consider $m < n$\footnote{The theoretical derivations herein give no constraints on $m$ and $n$.} --- namely, the succeeding linear inverse scheme is under-determined. Define 
\[
g_\mu(x) := \begin{cases}
			\sum_{i=1}^n x_i \log\frac{x_i}{\mu_i}, & x \geq 0 \\
            + \infty, & \text{else}
		 \end{cases}
\]
with the convention $0 \cdot \log 0 = 0$ and define $\KL(x| \mu):= g_\mu(x) + \delta_{\{1\}}(e^Tx)$, the Kullback--Leibler divergence. We look to solve the minimization problem
\begin{equation}\label{eq:primal}
   \min_{x \in \rr^n} \frac{1}{2 \lambda} \lVert Ax - b \rVert^2 + \KL(x| \mu).
\end{equation}
which we refer to as the \emph{primal problem} where $\lambda \geq 0$. The limiting $\lambda = 0$ case reduces the problem to
\begin{equation}\label{eq:primal0}
   \min_{x \in \rr^n} \delta_{b}(Ax) + \KL(x| \mu).
\end{equation}

The dual problems to \eqref{eq:primal} and \eqref{eq:primal0} are both given by 

\begin{equation}\label{eq:dual}
    \min_{y \in \rr^m} \frac{\lambda}{2} \lVert y \rVert^2 - b^Ty +  \log \left(\sum_{i=1}^n \mu_i \exp(A_i^T y)\right).
\end{equation}
where $A = [A_1 \cdots A_n]$.

\begin{remark}
    Suppose $\mu \in \Delta_n$ and $\mu_j = 0$ for some $j \in \{1,\dots,n\}$. Let $I^c = \{j: \mu_j = 0\}$, $E := \{x: x_j = 0 \text{ for } j \in I^c \}$ and $n' := |I|$. Then, 
    \begin{align}
         \min_{x \in \rr^n} \frac{1}{2 \lambda} \lVert Ax - b \rVert^2 + \KL(x| \mu)&=  \min_{x \in E \cap \Delta_n} \frac{1}{2 \lambda} \lVert Ax - b \rVert^2 + \sum_{i=1}^n x_i \log\frac{x_i}{\mu_i}  \nonumber \\ 
          &=  \min_{x \in E \cap \Delta_n} \frac{1}{2 \lambda} \lVert A_Ix - b \rVert^2 + \sum_{i \in I} x_i \log\frac{x_i}{\mu_i} \nonumber \\ 
           &=  \min_{x \in \rr^{n'}} \frac{1}{2 \lambda} \lVert A_Ix - b \rVert^2 + \KL(x|\mu_I) \label{eq:Reduced_primal}
    \end{align}
    where $\mu_I \in \rint \Delta_{n'}$. Hence, for simplicity, we may always assume our prior vector $\mu$ to have full-support. Moreover, given the unique minimzer $\Bar{x}_I$ to \eqref{eq:Reduced_primal}, we can obtain the minimzer $\Bar{x}$ to $\eqref{eq:primal}$ by setting $\Bar{x}_j = 0$ for $j \in I^c$ and $\Bar{x}_j = \Bar{x}_{I_j}$ for $j$ in $I$. 
\end{remark}

\subsubsection{No simplex constraint}

Relating to the problem considered in \cite{eriksson_NoteSolutionLarge_1980}, we also consider a modification of \eqref{eq:primal} and \eqref{eq:primal0}, in which  $\KL(x| \mu)$ is replaced by $g_\mu(x)$ --- namely where the simplex constraint is omitted and one seeks merely to recover a non-negative vector. That is, the minimization problems
\begin{equation}\label{eq:primal_noSimplex}
      \min_{x \in \rr^n} \frac{1}{2 \lambda} \lVert Ax - b \rVert^2 +  g_\mu(x).
\end{equation}
and
\begin{equation}\label{eq:primal_noSimplex0}
   \min_{x \in \rr^n} \delta_{b}(Ax) + g_\mu(x).
\end{equation}
whose duals are both given by

\begin{equation}\label{eq:dual_noSimplex}
    \min_{y \in \rr^m} \frac{\lambda}{2} \lVert y \rVert^2 - b^Ty + \sum_{i=1}^n \mu_i \exp(A_i^T y - 1).
\end{equation}



\subsection{Derivations of the duals}

In the route of Fenchel--Rockafellar duality, we note the nontrivial conjugate of $ \KL(x| \mu)$ and sketch the details of its proof which can be found in \cite[Example 11.12]{RockWets98}.

\begin{lemma}\label{lem:KL_dual}
  For $z \in \rr^n$,
  \[
   \KL^\ast(z| \mu) = \log \left(\sum_{i=1}^n \mu_i \exp(z_i)\right) =: L(z).
  \]
\end{lemma}
\begin{proof}
   The function $\vecmax(x) := \max_{1 \leq i \leq n}x_i$ is both the support function of $\Delta_n$ and the horizon function $L^\infty$ of $L$. Since $L^\ast$ is proper, convex, and lsc, $L^\infty$ is the support function of $\dom L^\ast$ and so we have that $\dom L^\ast$ and $\Delta_n$ share the same support function. 

    Hence, $\cl(\dom L^\ast) = \Delta_n$ and $\rint (\dom L^\ast) = \rint \Delta_n$. In particular, 
    \[
        \rint (\dom L^\ast) = \left\{v : v_j > 0, \sum_{i=1}^n v_j = 1 \right\}.
    \]

    Moreover, for $y \in \rint \Delta_n$, solving for $y = \nabla L(x)$ yields $x_i = \log \frac{y_i}{\mu_i}$ for $i \in \{1, \dots, n\}$, and so, by convexity of $L$, we have 
    \[
    L^\ast = \KL(\cdot | \mu)
    \]
    on $\rint (\dom L^\ast)$. As, $L^\ast$ and $\KL(\cdot | \mu)$ are convex and lsc, it follows that $L^\ast \equiv \KL(\cdot | \mu)$. Finally, as $\KL(\cdot | \mu)$ and $L$ are proper, convex, and lsc, the Fenchel--Moreau theorem gives that $\KL^\ast(\cdot | \mu) = L$.


    We note down the simple derivations for the dual of $g_\mu(x)$.
\end{proof}

\begin{proposition}
    For $z \in \rr^n$, 
    \[
    g_\mu^{\ast}(z) = \sum_{i=1}^n \mu_i \exp(z_i - 1).
    \]
\end{proposition}
\begin{proof}
    For simplicity, we view $g_\mu^{\ast}: \rr^n_{++} \to \rr$ to ensure differentiability of $g_\mu^{\ast}$ on its domain. This simplification does restrict the minimization problems in \eqref{eq:primal_noSimplex} and \eqref{eq:primal_noSimplex0} to the positive orthant, but \emph{seems} inconsequential in application. Setting $h(x) = x^Tz - g_\mu(x)$, we have
    \[
    \nabla h(x)_j = z_i - \log x_i - 1 + \log \mu_i = 0 \iff x_i = \mu_i \exp(z_i -1).
    \]
    By definition of the conjugate and given that $x^Tz - g_\mu(x)$ is concave, we have 
    \[
     g_\mu^{\ast}(z) = \sum_{i=1}^n z_i  \mu_i \exp(z_i -1) - \sum_{i=1}^n \mu_i \exp(z_i -1) \log(\mu_i \exp(z_i -1) / \mu_i) = \sum_{i=1}^n \mu_i \exp(z_i - 1).
    \]
\end{proof}


\subsection{Optimality conditions}

For reference, let us recall the setting and statement of the Fenchel--Rockafellar optimality conditions:

\begin{theorem} If $f: \ee_1 \to \Bar{\rr}$ and $g:\ee_2 \to \Bar{\rr}$ are closed, proper, and convex, $L: \ee_1 \to \ee_2$ is linear, and $0 \in \interior (\dom g - L(\dom f))$, then the following are equivalent:
\begin{enumerate}
    \item $p = d$, $\Bar{x} \in \argmin_x f(x) + g(Lx)$, $\Bar{y} 
    \in \argmax_y - f^\ast(L^\ast y) - g^\ast(-y)$
    \item $L^\ast\Bar{y} \in \partial f(\Bar{x})$, $-\Bar{y} \in \partial g(L\Bar{x})$
    \item $\Bar{x} \in \partial f^\ast(L^\ast\Bar{y})$, $L\Bar{x} \in \partial g^\ast (-\Bar{y})$.
\end{enumerate}
where $p := \inf_x f(x) + g(Lx)$ and $d := \sup_y - f^\ast(L^\ast y) - g^\ast(-y)$.
    
\end{theorem}


Since $\dom \lVert \cdot - b \rVert^2 = \rr^m$ and $KL(\cdot|\mu)$ is proper, the qualification condition $A(\dom KL(\cdot |\mu)) \cap \interior (\dom \lVert \cdot - b \rVert^2) \neq \emptyset$ is trivially satisfied. Moreover, as the regularizer and fidelity terms are both convex and lsc, the primal-dual optimality conditions for \eqref{eq:primal} and \eqref{eq:primal0} (via Fenchel--Rockafellar) read

\begin{align}
    Ax &+ \lambda y - b = 0 \label{eq:op1}\\
    x_j &= \frac{\mu_j \exp(A_j^Ty)}{\sum_{l=1}^n \mu_l \exp(A_l^Ty)} \qquad j \in \{1, \dots n\}. \label{eq:op2a}
\end{align}
where in \eqref{eq:op2a}, one has the entry-wise expression for $x = \nabla \KL^\ast(A^Ty|\mu)$.
The alternative problems  \eqref{eq:primal_noSimplex} and \eqref{eq:primal_noSimplex0} share the condition \eqref{eq:op1} whereas the second condition is replaced by

\begin{equation}\label{eq:op2_noSimplex}
     x_j = \mu_j \exp(A_j^Ty - 1)
\end{equation}

where in \eqref{eq:op2a}, one has the entry-wise expression for $x = \nabla g_\mu^\ast(A^Ty|\mu)$.

% \subsubsection{\textcolor{teal}{Reformulation of $2^{\text{nd}}$ condition... possibly remove}}
% \textcolor{teal}{
% Given that $\KL^\ast(\cdot|\mu)$ is proper, convex, and lsc, \eqref{eq:op2a} is equivalent to $A^Ty = \partial \KL(x|\mu)$. To compute $ \partial \KL(x|\mu)$, note that $\KL(x|\mu) = g_\mu(x) + \delta_{1}(e^Tx)$ where $g_\mu \in C^1$ on $\rr^n_+$ and $\delta_{\{1\}}(e^Tx)$ is proper, convex, and lsc. The sum rule can then be applied for $x \in \Delta_n$ to give
% \begin{align*}
% \partial \KL(x|\mu) &= \nabla g_\mu(x) + \partial \delta_{\{1\}}(e^Tx) \\
%             &= \begin{bmatrix}
%                 \log \frac{x_1}{\mu_1} + 1 \\
%                 \vdots \\
%                  \log \frac{x_n}{\mu_n} + 1
%             \end{bmatrix} + \spann \{e\}
% \end{align*}
% since $\delta_{\{1\}}(e^T \cdot)$ is the normal cone to the unit simplex. For  $x \notin \Delta_n$, $\partial \KL(x|\mu) = \emptyset$ as $\dom  \KL(\cdot|\mu) = \Delta_n$. This gives an alternative condition to \eqref{eq:op2a} of
% \begin{equation}\label{eq:op2b}
%     x_j = \mu_j \exp( A_j^Ty + \alpha)
% \end{equation}
% for some $\alpha \in \rr$. 
% }


\section{Algorithms}

\subsection{Restricting to the Simplex}

In deriving the succeeding algorithms, we give two directions of thought, which produce the same Newton procedure in the end and are thus backed by the same theoretical guarantees as discussed below.


We begin by directing solving the optimality conditions: plugging \eqref{eq:op2a} into \eqref{eq:op1}, we obtain the following nonlinear system
\[
P(y) := \underbrace{\frac{\sum_{j=1}^n \mu_j  \exp(A_j^T y_j) A_j}{\sum_{l=1}^n \mu_l  \exp(A_l^T y)}}_{\Tilde{P}(y)} + \lambda y - b = 0.
\]
Pursuing a Newton-type method to solve $P(y) = 0$, we compute $\nabla P(y) \in \rr^{m \times m}$. Defining $\Tilde{P}_i(y): \rr^m \to \rr$ by
\[
\Tilde{P}_i(y) := \frac{\sum_{j=1}^n \mu_j  \exp(A_j^T y) a_{ij}}{\sum_{l=1}^n \mu_l  \exp(A_l^T y)} =: \frac{f_i(y)}{g(y)}
\]
where $A = (a_{ij})_{1 \leq i, j \leq n}$, we have
\begin{align*}
    &\frac{\partial \Tilde{P}_i(y)}{\partial y_k}  = \frac{ \frac{\partial}{\partial y_k} f_i(y)}{g(y)} - \frac{f_i(y) \frac{\partial}{\partial y_k} g(y)}{g(y)^2} \\
    &= \frac{\sum_{j=1}^n a_{ij} \mu_j \exp(A_j^Ty) a_{kj}}{\sum_{l=1}^n \mu_l  \exp(A_l^T y)} - \left(\frac{\sum_{j=1}^n \mu_j  \exp(A_j^T y) a_{ij}}{\sum_{l=1}^n \mu_l  \exp(A_l^T y)}\right)\left(\frac{\sum_{l=1}^n \mu_l  \exp(A_l^T y) a_{k_l}}{\sum_{l=1}^n \mu_l  \exp(A_l^T y)} \right) \\
    &= \sum_{j=1}^n a_{ij} x_j a_{kj} - \left(\sum_{j=1}^n a_{ij} x_j \right) \left( \sum_{l=1}^n a_{kl}  x_l \right).
\end{align*}
This gives 
\[
\nabla \Tilde{P}(y) = A \diag(x) A^T - Ax(Ax)^T = A(\diag(x) - xx^T)A^T
\]
where $\diag(x)$ is the diagonal matrix with diagonal entries populated by the entries of $x$. Hence,
\[
\nabla P(y) = A(\diag(x) - xx^T)A^T + \lambda I.
\]
Furthermore, from the lemma below, we easily find that $A(\diag(x) - xx^T)A^T$ is symmetric positive semi-definite, guaranteeing the invertibility of  $\nabla P(y)$ for all $y \in \rr^m$ for $\lambda > 0$.



\begin{lemma}
    Let $x \in \Delta_n$. Then,
\[
    S := \diag(x)
 - x x^T \in \mathbb{S}_+^n
 \]
 \begin{proof}
     $S$ is obviously symmetric and for $i \in \{1, \dots, n\}$, we have
     \[
         |s_{ii}| - \sum_{j \neq i} |s_{ij}| = x_i - x_i^2 - \sum_{j \neq i} x_i x_j = x_i (1 - \sum_{j=1} x_j) = 0.
     \]
     Hence, $S$ is diagonally dominant, and so by Gershgonin's Circle theorem \cite[\S{6}]{Horn_Johnson_2012}, $S \succeq 0$.
 \end{proof}
\end{lemma}

Looking to solve \begin{equation}\label{eq:Newton_P}
\nabla P(y^k)d^k = - P(y^k).
\end{equation}

where $y^{k+1} = y^k + d^k$ as in a conventional Newton method and recover $x$ via \eqref{eq:op2a}, we present the following Newton-type scheme, making use of the above computations. It should be noted that this is not a true Newton iteration on the optimality conditions \eqref{eq:op1} and \eqref{eq:op2a}, and so, as derived, one has no immediate guarantees of convergence. However,  Algorithm \ref{alg:1} coincides exactly to performing a conventional Newton method on the Jacobian of the dual objective function, and therefore one obtains the desired convergence properties by examining the problem in this way. 

Denoting the objective function in \eqref{eq:dual} by $d(y)$, we have 
\[
\nabla d(y) = Ax - b + \lambda y
\]
where $x := x(y)$ is the same function of $y$ as given in \eqref{eq:op2a} and 
\[
\nabla^2 d(y) = A(\diag(x) - xx^T) A^T + \lambda I.
\]
where we leave the explicit computations in the next section. In this way, one finds that linear system in \eqref{eq:Newton_P} is precisely the same as the Newton equation 
\begin{equation}\label{eq:Newton_D}
    \nabla^2 d(y^k)d^k = -\nabla d(y^k),
\end{equation}
where we emphasize that the difference comes in the point of view: solving the optimality conditions versus solving the dual. While, the perspective of solving for the optimality conditions may seem unneeded given that the dual approach here is what is used to guarantee convergence --- we are performing a \emph{true} Newton iteration --- the first perspective shows us that the Newton iteration on the dual Jacobian embeds the primal solution $x$\footnote{More precisely, it produces iterates $x^k$ that converge to the primal solution $\Bar{x}$ as $y^k \to y$ where $\Bar{y}$ is the dual solution.} in each of its iterations.

\subsubsection{Explicit computations for $\nabla d(y)$ and $\nabla^2d(y)$}

By the chain rule, one immediately sees that
\[
\nabla d(y) = A\nabla h(u) - b + \lambda y
\]
where $h(u) = \log (\sum_{i=1}^n \mu_i \exp{(u_i)})$ and we evaluate $u = A^Ty$. Clearly, 
\[
[\nabla h(u)]_j = \frac{\mu_j \exp{(u_j})}{\sum_{i=1}^n \mu_i \exp{(u_i)}}
\]
and so evaluating $u = A^Ty$, we recover precisely the definition of $x^k$ in terms of $y^k$ as seen in the algorithms outlined below. To compute $\nabla^2 d(y)$, a second application of the chain rule gives that
\[
\nabla^2 d(y) = A \nabla^2 h(u) A^T + \lambda I,
\]
--- again, evaluating $u = A^Ty$. Computing $\nabla^2 h(u)$, observe that
\[
[\nabla^2 h(u)]_{jj} = \frac{\mu_j \exp{(u_j)}\sigma - (\mu_j \exp{(u_j}))^2}{\sigma^2} = \frac{\mu_j \exp(u_j)}{\sigma} \frac{(\sigma - \mu_j \exp{(u_j)})}{\sigma}
\]
and
\[
[\nabla^2 h(u)]_{ij} = \frac{0 - \mu_j \exp{(u_j})\mu_i \exp{(u_i)}}{\sigma^2} 
\]
for $\sigma = \sum_{l=1}^n \mu_l \exp{(u_l)}$. Making the evaluation $u = A^Ty$ then gives
\[
[\nabla^2 h(A^Ty)]_{jj} = x_j(1 - x_j)
\]
and 
\[
[\nabla^2 h(A^Ty)]_{ij} = -x_jx_i.
\]
Hence, 
\[
\nabla^2 d(y) = A \nabla^2(\diag(x) - xx^T) A^T + \lambda I,
\]

\begin{remark}
    The above discussion concerning the appearance of a sequence of iterates $x^k := x(y^k)$ in the Newton equation that converge to the primal solution $\Bar{x}$ as $y^k \to \Bar{y}$ is not a fortunate coincidence particular to our framework. In fact, whenever $f^{\ast}$ is differentiable (here $f$ is as in the setting of Fenchel--Rockafellar duality), one will see $A \nabla f^\ast(A^Ty)$ in $\nabla d(y)$ by a simple application of the chain rule to $\nabla F(y)$ where $F: \rr^m \to \rr$ is the map $y \mapsto f^\ast(A^Ty)$. The optimality condition $\Bar{x} = f^\ast(A^T \Bar{y})$ then gives $\nabla d(y) = Ax + \nabla g^\ast(-y)$. However, what is particular to our setting is the reappearance of the iterates $x^k$ in $\nabla^2 d(y)$. Given the same fidelity, the Hessian will be of the form $\nabla^2 d(y) = AH(y)A^T + \lambda I$ for some function $H(y)$ by the chain rule. In our case, the function $H(y^k)$ turns out a be a simple function of the iterates, namely $\diag(x) - x^k(x^k)^T$.
\end{remark}

\paragraph{Convergence of Algorithm \ref{alg:1}} Algorithm \ref{alg:1} gives local convergence to the primal solution $\Bar{x}$ for the problem \eqref{eq:primal} since $\nabla^2d$ is invertible everywhere, and in particular at $\Bar{x}$. Moreover, as $\nabla^2 d$ is continuously differentiable and hence locally Lipschitz at $\Bar{x}$, one has quadratic convergence near the solution. However, for the $\lambda=0$ case \eqref{eq:primal0}, one cannot guarantee invertibility and hence convergence unless certain assumptions are made on $A$. 

\paragraph{Convergence of Algorithms \ref{alg:armijo} and \ref{alg:NonMonoArmijo}} Algorithms \ref{alg:armijo} and \ref{alg:NonMonoArmijo} provide global convergence to the primal solution $\Bar{x}$ for the problem \eqref{eq:primal} since $d \in C^2$ --- thus guaranteeing convergence of the iterates $y^k \to \Bar{y}$ --- and $\Bar{x}$ is a continuous function of $\Bar{y}$ via the optimality conditions. Given that $\nabla^2 d(\Bar{y})$ is positive definite and locally Lipschitz, one will eventually cease to take gradient steps and take full step sizes $t_k = 1$, thus entering the local Newton's method where one has quadratic convergence as mentioned above. However, similar to the case for Algorithm 1, one cannot guarantee convergence rates nor convergence in problem \eqref{eq:primal0}.

\begin{algorithm}[h]
\caption{Local Newton method on the dual Jacobian}\label{alg:1}
\begin{algorithmic}[1]
\Require $A \in \rr^{m \times n}$, $\mu \in \rint \Delta_n$, $b \in \rr^m$, and $\epsilon > 0$.
\Ensure $y \in \rr^m$ and $x \in \rr^n$.
\State Choose $y^0 \in \rr^m$. Define $x^0 \in \rr^n$ via \[
x_j^0 := \frac{\mu_j \exp(A_j^Ty^0)}{\sum_{l=1}^n \mu_l \exp(A_l^Ty^0)} \qquad j \in \{1, \dots n\}.
\]
Set $k:= 0$.
\State If $\lVert \nabla d(y^k) \rVert \leq \epsilon$: STOP. \label{step:2}
\State Determine $d^k$ as the solution of \[
\underbrace{(A(\diag(x^k) - x^k (x^k)^T)A^T + \lambda I)}_{\nabla^2 d(y^k)}d^k = \underbrace{-Ax^k - \lambda y^k + b}_{- \nabla d(y^k)}.
\]
Set $y^{k+1} := y^k + d^k$. Define $x^{k+1}$ by 
\[
x_j^{k+1}:=\frac{\mu_j \exp(A_j^Ty^{k+1})}{\sum_{l=1}^n \mu_l \exp(A_l^Ty^{k+1})} \qquad j \in \{1, \dots n\}.
\]
\State $k \gets k+1$. Go to \eqref{step:2}.
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h]
\caption{Globalized Newton method using Armijo backtracking}\label{alg:armijo}
\begin{algorithmic}[1]
\Require $A \in \rr^{m \times n}$, $\mu \in \rint \Delta_n$, $b \in \rr^m$, and $\epsilon > 0$. Hyperparameters: $\rho>0$, $p > 2$, $\beta \in (0,1)$, $\sigma \in (0, 1/2)$, $m \in \nn$.
\Ensure $y \in \rr^m$ and $x \in \rr^n$.
\State Choose $y^0 \in \rr^m$. Define $x^0 \in \rr^n$ via \[
x_j^0 := \frac{\mu_j \exp(A_j^Ty^0)}{\sum_{l=1}^n \mu_l \exp(A_l^Ty^0)} \qquad j \in \{1, \dots n\}.
\]
Set $k:= 0$.
\State If $\lVert \nabla d(y^k) \rVert \leq \epsilon$: STOP. \label{step:2-1}
\State Find a solution $d^k$ of the Newton equation \[
\underbrace{(A(\diag(x^k) - x^k (x^k)^T)A^T + \lambda I)}_{\nabla^2 d(y^k)}d^k = \underbrace{-Ax^k - \lambda y^k + b}_{- \nabla d(y^k)}.
\]
If no solution can be found or if \[
\nabla d(y^k)^Td^K > -\rho \lVert d^k \rVert^p
\]
then put $d^k := - \nabla d(y^k)$.
\State Determine $t_k$ via 
\[
t_k := \max_{l \in \nn_0} \left\{ \beta^l : d(y^k + \beta^ld^k) \leq d(y^k) + \beta^l\sigma \nabla d(y^k)^T d^k \right\}
\]
\State Set $y^{k+1} := y^k + t_k d^k$. Define $x^{k+1}$ by 
\[
x_j^{k+1}:=\frac{\mu_j \exp(A_j^Ty^{k+1})}{\sum_{l=1}^n \mu_l \exp(A_l^Ty^{k+1})} \qquad j \in \{1, \dots n\}.
\]
\State $k \gets k+1$. Go to \eqref{step:2-1}.
\end{algorithmic}
\end{algorithm}

Similar to Algorithm \eqref{alg:armijo},  Algorithm \eqref{alg:NonMonoArmijo} globalizes the convergence of the Local Newton's method used in Algorithm \eqref{alg:1} by opting for a gradient step when the Newton step does not yield sufficient decrease and by introducing a dynamic learning rate $t_k$ chosen by the Amrijo rule. The difference between  Algorithm \eqref{alg:NonMonoArmijo} and \eqref{alg:armijo} lies in the latter point, whereby the learning rate $t_k$ in Algorithm \eqref{alg:NonMonoArmijo} is selected by a somewhat more sophisticated adaptation to the Armijo rule which we refer to as Non-monotone Armijo and which is studied in \cite{Grippo1986Nonmonotone} and \cite{Grippo1989}.


\begin{algorithm}[h!]
\caption{Globalized Newton method using non-monotone Armijo backtracking}\label{alg:NonMonoArmijo}
\begin{algorithmic}[1]
\Require $A \in \rr^{m \times n}$, $\mu \in \rint \Delta_n$, $b \in \rr^m$, and $\epsilon > 0$. Hyperparameters: $\rho>0$, $p > 2$, $\beta \in (0,1)$, $\sigma \in (0, 1/2)$, $m \in \nn$.
\Ensure $y \in \rr^m$ and $x \in \rr^n$.
\State Choose $y^0 \in \rr^m$. Define $x^0 \in \rr^n$ via \[
x_j^0 := \frac{\mu_j \exp(A_j^Ty^0)}{\sum_{l=1}^n \mu_l \exp(A_l^Ty^0)} \qquad j \in \{1, \dots n\}.
\]
Set $k:= 0$.
\State If $\lVert \nabla d(y^k) \rVert \leq \epsilon$: STOP. \label{step:2-3}
\State Find a solution $d^k$ of the Newton equation \[
\underbrace{(A(\diag(x^k) - x^k (x^k)^T)A^T + \lambda I)}_{\nabla^2 d(y^k)}d^k = \underbrace{-Ax^k - \lambda y^k + b}_{- \nabla d(y^k)}.
\]
If no solution can be found of if \[
\nabla d(y^k)^Td^K > -\rho \lVert d^k \rVert^p
\]
then put $d^k := - \nabla d(y^k)$ and $m_k=0$. Otherwise, set $m_k:= \min \{m_{k-1}+1, m\}$.
\State Determine $t_k$ via 
\[
t_k := \max_{l \in \nn_0} \left\{ \beta^l : d(y^k + \beta^ld^k) \leq R_k + \beta^l\sigma \nabla d(y^k)^T d^k \right\}
\]
where \[
R_k := \max_{k - m_k \leq j \leq k} d(y^j).
\]
\State Set $y^{k+1} := y^k + t_k d^k$. Define $x^{k+1}$ by 
\[
x_j^{k+1}:=\frac{\mu_j \exp(A_j^Ty^{k+1})}{\sum_{l=1}^n \mu_l \exp(A_l^Ty^{k+1})} \qquad j \in \{1, \dots n\}.
\]
\State $k \gets k+1$. Go to \eqref{step:2-3}.
\end{algorithmic}
\end{algorithm}

\subsection{No simplex constraint}

In tackling \eqref{eq:primal_noSimplex} and \eqref{eq:primal_noSimplex0}, there is no need to reintroduce the algorithms already written above since we still (for the time being) propose to implement a globalized Newton method on the dual of the Jacobian. The only difference is that the dual objective \eqref{eq:dual_noSimplex} is now different and therefore the computations of $\nabla d(y)$ and $\nabla^2 d(y)$ as well the optimality condition for $\Bar{x}$ is altered. Running through the computations in a similar yet simpler manner as above, one obtains 
\[
\nabla d(y^k) = Ax^k - b + \lambda y^k
\]
and 
\[
\nabla^2 d(y^k) = A \diag(x^k)A^T + \lambda I
\]
for the iterates $y^k$ where 
\[
x^k_i = \mu_i \exp{(A_i^Ty - 1)}
\]
for $i = 1, \dots n$.



\input{asymptotic-view.tex}

% \section{A brief note on the convergence of $x^k \to \Bar{x}$}

% In Algorithms \eqref{alg:armijo} and \eqref{alg:NonMonoArmijo} outlined above, we have global convergence of the iterates $y^k \to \Bar{y}$ where $\Bar{y}$ is the unique solution to the dual problem \eqref{eq:dual}. Moreover, this convergence is quadratic for $k$ sufficiently large. At $\Bar{y}$, the optimality conditions give 
% \[
% \Bar{x} =  F(\Bar{y})
% \]
% where $F:\rr^m \to \rr^n$ is the RHS of \eqref{eq:op2a}. The question is then: what can be said about $x^k$? Since $F$ is continuous, we have  $x^k \to \Bar{x}$ as $y^k \to \Bar{y}$. We now quantify this convergence. $F$ can be written as the composition of three Lipschitz functions $F = \softmax \circ \; h \circ A^T$ where $h: \rr^n \to \rr^n$ is
% \[
% h(z) := z + \begin{bmatrix}
%     \ln \mu_1 \\
%     \vdots \\
%     \ln \mu_n
% \end{bmatrix}.
% \]
% The softmax function is 1-Lipschitz (see e.g. \cite[Proposition 4]{Gao2017OnTP}) and so is $h$ trivially. Therefore we find that 
% \begin{equation}\label{eq:PrimalDual_bound}
% \lVert x - x^k \rVert \leq \lVert A^T \rVert \lVert \Bar{y} - y^k \rVert = \lVert A \rVert \lVert \Bar{y} - y^k \rVert.
% \end{equation}

\section{Derivative of the optimal-value function}


In this brief section, we compute the derivative of the optimal-value function for both the dual and primal objectives parameterized by $\tau$. 

\subsection{Primal}


In the following result, $f^{\pi}(x, \tau)$ is the perspective transform of the function $f$ given by 
\[
f(x) := \delta_{\{1\}}(e^Tx).
\]

\begin{lemma}
    Define
    \[
    \psi(x, \tau) := \frac{1}{2 \lambda}\lVert Ax - b \rVert^2 + g_\mu(x) + f^{\pi}(x, \tau)
    \]
    and
    \[
    v(\tau) := \inf_x \psi(x, \tau).
    \]
    Then,
    \[
    \partial v(\Bar{\tau}) = \left\{ \Bar{\rho} \in \rr: \Bar{\rho} e = \frac{1}{\lambda}A^T(A\Bar{x}-b) + \Bar{x}^T \nabla g_{\mu}(\Bar{x}) \right\}
    \]
    where $\Bar{x} = \argmin_x \psi(x, \bar{\tau})$. Namely,  $\partial v(\Bar{\tau})$ is a singleton and thus $v$ is differentiable.
\end{lemma}

\begin{proof}
    Applying \cite[Theorem 16.3]{rockafellar-1970}, we have
    \[
    f^\ast(y) = \inf \{ \alpha : \alpha e = y \} = e^Ty + \delta_{\rr \{e\}}(y).
    \]
    Then, by \cite[Corollary 13.5.1]{rockafellar-1970}, for $\tau > 0$, $f^{\pi}(x, \tau) = \sigma_D(x, \tau)$ where
    \begin{align*}
        D &= \{(y, \beta): f^\ast(y) \leq - \beta \} \\
            &= \{(y, \beta): \exists \eta \in \rr \text{ s.t. } y = \eta e, \; \eta \leq - \beta \} \\
            &= \{(\eta e, \beta): \eta + \beta \leq 0 \}.
    \end{align*}
    We can then write $D = F(C)$ for $F: \rr^2 \to \rr^n \times \rr$ given by $F(\eta, \beta) = (\eta e, \beta)$ and $C = \{(\beta, \eta) : \beta + \eta \}$. Then, by \cite[Theorem 6.4.3]{RockWets98}, we have
    \begin{align*}
        N_D(\Bar{\eta}e, \Bar{\beta}) &= \{(z, \alpha) : \overbrace{F^\ast(z, \alpha)}^{(e^Tz, \alpha)} \in N_C(\Bar{\eta}, \Bar{\beta}) \} \\ &= \left\{ (z, \alpha) : (e^Tz, \alpha) \in 
        \begin{cases}
            \rr_+\{(1 1)^T\}, &\; \Bar{\beta} + \bar{\eta} = 0 \\ \{0\}, &\; \Bar{\beta} + \bar{\eta} < 0 
        \end{cases} \right\}.
    \end{align*}
    Hence, $(\Bar{x}, \Bar{\tau}) \in N_D(\Bar{\eta}e, \Bar{\beta}) \Longleftrightarrow (e^T\Bar{x}, \Bar{\tau}) \in \rr \{(1 \; 1)^T\}, \; \Bar{\eta} + \Bar{\beta} = 0$ since $e^T\Bar{x} = \Bar{\tau}$. Therefore, 
    \begin{align*}
         \partial f^\pi(x, \tau) &= \{(\Bar{\eta}e, \Bar{\beta}) :  \Bar{\eta} + \Bar{\beta} = 0 \} \\
         &= \{(\Bar{\eta}e, -\Bar{\eta}) :  \Bar{\eta} \in \rr \} \\
         &= \rr \{(e, -1)\}.
    \end{align*}

    We now recall the following fact: If $\psi: \rr^n \times \rr^p \to \Bar{\rr}$ is closed, proper, and convex, and $\varphi(p) = \inf_x \psi(x,p)$, then 
    \[
    \partial \varphi (\Bar{p}) = \{v: (0,v) \in \psi(\Bar{x}, \Bar{p}) \}
    \]
    for any $\Bar{x} \in \argmin_x \psi(x, \Bar{p})$.

    Thus, since $\psi(x, \tau)$ is closed, proper, and convex on $\rr^n \times \rr$, we have that $\Bar{p} \in \partial v(\Bar{\tau})$ if and only if 
    \[
    (0, \Bar{p}) \in \partial \psi(\Bar{x}, \Bar{\tau}) = \left\{ \frac{1}{\lambda}A^T(A\Bar{x}-b) + \nabla g_\mu(\Bar{x}) \right\} \times \{0\} + \partial f^\pi(\Bar{x}, \Bar{\tau}).
    \]
    This is equivalent to
    \[
     \Bar{\rho} e = \frac{1}{\lambda}A^T(A\Bar{x}-b) + \Bar{x}^T \nabla g_{\mu}(\Bar{x})
    \]
    which completes the proof.
\end{proof}

\subsection{Dual}


\begin{lemma}
    Let 
    \[
    \psi(y, \tau) = \frac{\lambda}{2} \lVert y \rVert^2 - b^Ty + \tau \log (\tau^{-1} \sum_{i=1}^n \mu_i \exp{(A_i^Ty)})
    \]
    and consider 
\[
    v(\tau) = \inf_{y \in \rr^m}  \psi(y, \tau),
\]
the optimal-value function of the dual objective parameterized by $\tau$. For $\bar{\tau} > 0$, we have
\[
v'(\Bar{\tau}) =  \log (\sum_{i=1}^n \mu_i \exp{(A_i^T\Bar{y})}) - \log \bar{\tau} - 1
\]
where $\Bar{y} = \argmin_y \psi(y,\bar{\tau})$.
\end{lemma}

\begin{proof}
    Let $g(\tau) =  \argmin_y \psi(y,\tau)$ be the solution map parameterizede by $\tau$ which is well defined by strong convexity of $\psi$ in the first argument and set $F(y, \tau) = \nabla_y \psi(y, \tau)$. Note that $F(\Bar{y}, \Bar{\tau}) = 0$ and $\nabla^2_yF(\Bar{y}, \Bar{\tau})$ is positive definite by strong convexity, hence invertible, and so by the Implicit Function Theorem, $g$ is differentiable (in fact $C^\infty)$ at $\Bar{\tau}$. Since $v(\bar{\tau}) = \psi(g(\bar{\tau}), \Bar{\tau})$ and $\nabla_{\tau} g(\bar{\tau})$ exists, we may apply the chain rule to obtain:
    \[
     v'(\bar{\tau}) = \nabla_\tau g(\bar{\tau}) \nabla_{y} \psi(\bar{y}, \Bar{\tau}) + \nabla_\tau \psi(\Bar{y}, \Bar{\tau}).
    \]
    As $ \nabla_{y} \psi(\bar{y}, \Bar{\tau}) = 0$, we have $v'(\bar{\tau}) = \nabla_\tau \psi(\Bar{y}, \Bar{\tau})$ which completes the proof.
\end{proof}

\begin{remark}
    In the same way, we can obtain the derivative of the optimal-value function parameterized by any of the variables $A, b, c$, and $\lambda$. 
\end{remark}


\begin{remark}
    Perhaps an alternative proof can appeal to \cite{Bonnans2000} by first noting that $\psi(y, \tau)$ and 
\begin{equation}\label{eq:dual_derivative_tau}
\nabla_\tau \psi(y, \tau) = \log (\sum_{i=1}^n \mu_i \exp{(A_i^Ty)}) - \log \tau - 1
\end{equation}
are both continuous. Then, by \cite[Theorem 4.13]{Bonnans2000}, if we can verify the so-called \emph{inf-compactness condition} of \cite[page 272]{Bonnans2000}, then \eqref{eq:dual_derivative_tau} will coincide with $v'(\bar{\tau})$. 
\end{remark}

\section{Perturbation analysis of the solution map}

\textcolor{teal}{\subsection*{Current summary of sensitivity results:}
Let $x_b, x_{b'}, x_\lambda, x_{\lambda'} \dots$, be the optimal values for the primal problem characterized by $b, b', \lambda, \lambda', \dots$ and let $y_b^\epsilon$ be an $\epsilon$-optimal solution to the dual problem characterized by $b$  (i.e. $d(y_b^\epsilon)$ is within $\epsilon$ of the optimal value) and so on. So far we have established:
\begin{enumerate}
    \item \[
\lVert x_b - x_{b'} \rVert  \leq \frac{\lVert A \rVert}{\lambda} \rVert b - b' \rVert
\]
for all $b, b' \in \rr^m$.
    \item \[
\lVert x_\lambda - x_{\lambda'}\lVert \leq \left(\frac{\lVert A \rVert}{\lambda}\right) \left(\frac{\lVert A \rVert + \lVert b \rVert}{\lambda'}\right) | \lambda - \lambda' |
\] for all $\lambda$ in a neighbourhood of $\lambda'$.
 \item \[
\lVert x_\lambda - x_{\lambda'}\lVert \leq \textcolor{red}{2} \left(\frac{\lVert A \rVert}{\lambda}\right) \left(\frac{\lVert A \rVert + \lVert b \rVert}{\lambda'}\right) | \lambda - \lambda' |
\] for all $\lambda, \lambda' > 0$.
\item \[
\lVert y_b^\epsilon - y_{b'}\lVert \leq \frac{\textcolor{red}{2}}{\lambda} \lVert b - b'\rVert + \sqrt{\frac{2 \epsilon}{\lambda}}
\]
for all $b, b' \in \rr^m$.
\item \[
\lVert y_\lambda - y_{\lambda'}\lVert \leq \left(\frac{\lVert A \rVert + \lVert b \rVert}{\lambda'\lambda}\right) | \lambda - \lambda' | + \sqrt{\frac{2 \epsilon}{\lambda}}
\]
for all $b, b' \in \rr^m$.
\end{enumerate}
}

The following subsections each explore a different route in examining the sensitivity of the solution-map of \eqref{eq:primal} as a function of some of the parameters (e.g. $b$, $\lambda$, $A$). We begin with a lemma that will be used to describe the sensitivity of the primal solution as a function of the dual solution using the primal-dual optimality conditions. For the proof of Lemma \ref{lem:primal_dual_bound}, we use the following trivial result on the composition of Lipschitz functions.

\begin{proposition}\label{prop:lipschitz_composition}
    Let $\{E_j\}_{j=1}^{n+1}$ be Euclidean spaces and $(f_j)_{j=1}^n$ be a finite sequence of Lipschitz functions $f_j: \ee_j \to \ee_{j+1}$ of modulus $\kappa_j$ respectively. Then, the map $F = f_n \ \circ \cdots \circ f_1$ is $\kappa_1 \cdots \kappa_n$-Lipschitz.
\end{proposition}
\begin{proof}
    Simple induction using the definition of Lipschitz continuity.
\end{proof}

\begin{lemma}\label{lem:primal_dual_bound}
    Let $F: \rr^m \to \rr^n$ be the map $y \mapsto \nabla \KL^\ast(A^Ty|\mu)$. Namely, 
    \[
    [F(y)]_j = \frac{\mu_j \exp(A_j^Ty)}{\sum_{l=1}^n \mu_l \exp(A_l^Ty)} \qquad j \in \{1, \dots n\}
    \]
    Then, $F$ is $\lVert A \rVert - Lipschitz$ on $\rr^m$.
\end{lemma}

\begin{proof}
    Note that $F$ can be decomposed as  $F = \softmax \circ \; h \circ A^T$ where $\softmax: \rr^n \to \rr^n$ is defined entry-wise by
    \[
    [\softmax(z)]_j = \frac{\exp(z_j)}{\sum_{l=1}^n \exp(z_l)} \qquad j \in \{1, \dots n\}
    \]
    and $h: \rr^n \to \rr^n$ is
\[
h(z) := z + \begin{bmatrix}
    \ln \mu_1 \\
    \vdots \\
    \ln \mu_n
\end{bmatrix}.
\]
The softmax function is 1-Lipschitz (see e.g. \cite[Proposition 4]{Gao2017OnTP}) and so is $h$ trivially. Hence, $F$, by Proposition \ref{prop:lipschitz_composition}, is Lipschitz with modulus $1 \cdot 1 \cdot \lVert A^T \rVert = \lVert A \rVert$.
\end{proof}

\begin{remark}
    Instead of appealing to \cite[Proposition 4]{Gao2017OnTP}, we can instead reference \cite[Example 5.15]{firstorderBeck} which shows that $\logsumexp(x)$ is $1$-smooth, hence $\nabla \logsumexp(x) = \softmax(x)$ is $1$-Lipschitz.
\end{remark}

As a brief application of Lemma \ref{lem:primal_dual_bound}, let $(x^k)$ and $(y^k)$ be the sequence of iterates generated by any one of the aforementioned algorithms. Then, for $\Bar{x}$ and $\Bar{y}$ being the unique solutions of the primal and dual problems, we have that for all $k \in \nn$,
\begin{equation}\label{eq:PrimalDual_bound}
\lVert x - x^k \rVert \leq \lVert A^T \rVert \lVert \Bar{y} - y^k \rVert = \lVert A \rVert \lVert \Bar{y} - y^k \rVert.
\end{equation}




\subsection{$2^\text{nd}$-order growth condition of \cite{Bonnans2000}}

\subsubsection{Sensitivity to $b$}


In many cases arising from physical experiments, one does not have access to $Ax$, instead one observes (or assumes to observe) some noisy observations
\[
b = Ax + \eta
\]
for some unknown $\eta \in \rr^m$. Let us define 
\[
F_b(y) :=  \frac{\lambda}{2} \lVert y \rVert^2 - b^Ty +  \log \left(\sum_{i=1}^n \mu_i \exp(A_i^T y)\right).
\]
to be the objective function in \eqref{eq:dual} parameterized by the vector $b$ and $y_b := \argmin_{y \in \rr^m}F_b(y)$ to be its unique solution. By \cite[Proposition 4.32]{Bonnans2000}, we have
\begin{equation}\label{eq:BS_bound_dual}
\lVert y_b - y_{b'}\lVert \leq \frac{\kappa}{c} 
\end{equation}
when $F_b - F_{b'}$ is $\kappa$-Lipschitz and $c>0$ is the constant in the second-order growth condition of $F_b$, i.e. 
\[
F_b(y) \geq F_b(y_b) + c \lVert y - y_b \rVert^2
\]
for all $x$ in a neighbourhood of $x_b$. Since $F_b - F_{b'} = y^T(b'-b)$, we have that  $F_b - F_{b'}$ is $\lVert b' - b \rVert$-Lipschitz on $\rr^m$. To mimic the formulation of \cite[Example 4.33]{Bonnans2000}, note that we may rewrite $F_b(y)$ as 
\[
F_b(y) =  \frac{\lambda}{2} \lVert y - b/\lambda \rVert^2 +  \underbrace{\log \left(\sum_{i=1}^n \mu_i \exp(A_i^T y)\right) - \frac{1}{\lambda^2}b^Tb}_{f(y)}
\]
where $f$ is the closed, proper, convex function in \cite[Example 4.33]{Bonnans2000}. Then, as we are in the same setting from \cite[Example 4.33]{Bonnans2000}, we immediately find that $F_b(y)$ satisfies the second-order growth condition at $y_b$ with the constant $\lambda / 2$. Hence, taking $\kappa = \lVert b - b'\rVert$ and $c = \lambda / 2$ in \eqref{eq:BS_bound_dual}, we have
\[
\lVert y_b - y_{b'}\lVert \leq \frac{2}{\lambda} \lVert b - b'\rVert.
\]
Applying Lemma \ref{lem:primal_dual_bound}, we obtain the bound
\textcolor{red}{
\[
\lVert x_b - x_{b'}\lVert \leq \frac{2\lVert A \rVert}{\lambda} \lVert b - b'\rVert.
\]
}
where $x_b$ and $x_{b'}$ are the unique minimzers of the primal problem parameterized by $b$ and $b'$ respectively. Namely, $\lVert x_b - x_{b'}\lVert = O(\lVert b - b' \rVert)$. If instead we assume $y_b^{\epsilon}$ is an $\epsilon$-optimal solution of the dual problem parameterized by $b$, then 
\[
\lVert y_b^\epsilon - y_{b'}\lVert \leq \frac{2}{\lambda} \lVert b - b'\rVert + \sqrt{\frac{2 \epsilon}{\lambda}}
\]
by \cite[Proposition 4.32]{Bonnans2000}.


To tie in a probabilistic framework, suppose $b' = b + \eta$ where $\eta$ has i.i.d. $\mathcal{N}(0,\sigma^2)$ entries. Then, 
\[
 \text{RMSE}( x_b - x_{b'}) = \frac{\ee \lVert x_b - x_{b'}\rVert}{\sqrt{n}} \leq \frac{2 \lVert A \rVert \sigma}{\lambda}.
\]
By applying Bernstein's inequality \cite[Corollary 2.8.3]{Vershynin_2018} to the subexponential mean zero random variables $\eta_1^2 - \sigma^2, \dots, \eta_n^2 - \sigma^2$, we obtain the following probability estimate for all $\delta > 0$:
\begin{align*}
    \P( \lVert x_b - x_{b'} \rVert / \sqrt{n} > \delta) &\leq   \P \left( \lVert \eta \rVert / \sqrt{n} > \frac{\lambda\delta}{2 \lVert A \rVert} \right) \\
     &=  \P \left( \frac{\sum_{i=1}^n (\eta_i^2 - \sigma^2)}{n} > \frac{\lambda^2\delta^2}{4 \lVert A \rVert^2} \right) \\
     &\leq 2 \exp{\left(-C \min \left(\frac{\lambda^2\delta^2 + 4\sigma^2 \lVert A \rVert^2}{4\sigma^2 \lVert A \rVert^2}, \frac{(\lambda^2\delta^2 + 4\sigma^2 \lVert A \rVert^2)^2}{16 C'\sigma^4 \lVert A \rVert^4} \right)n\right)}
\end{align*}
where $C, C' > 0$ are absolute constants. In the last inequality, we used that $\lVert \eta_i^2 \rVert_{\psi_1} = O(\sigma^2)$. If one wants, it is likely possible to compute the absolute constant $C$ and $C'$ explicitly. In summary, we see that the probability of the RMSE being large decreases exponentially in the dimension. 

\subsubsection{Sensitivity to $\lambda$}

Letting $x_\lambda$ and $x_{\lambda'}$ be the minimizers of the primal problem \eqref{eq:primal} parameterized by $\lambda$ and $\lambda'$ respectively, we can adapt the arguments from the above section to obtain an upper bound on $\lVert x_\lambda - x_{\lambda'} \rVert$ as a function of $(\lambda, \lambda')$. Letting $F_\lambda(y)$ be the dual objective function --- now parameterized by $\lambda$ instead of $b$ --- we have the same constant $c = \lambda / 2$ for the second-order growth condition (the function is indeed the same). To apply \cite[Proposition 4.32]{Bonnans2000}, we would like for $H(y) := F_{\lambda}(y) = F_{\lambda'}(y) = \frac{\lambda - \lambda'}{2}\lVert y \rVert^2$ to be Lipschitz on the set for which we are optimizing over --- namely $\rr^m$ ---, yet $H$ is not Lipschitz. However, $H \in C^1$ and so by the Mean-Value Theorem, $H$ is Lipschitz on any compact set $C$ with Lipschitz constant
\[
\kappa := \sup_{y \in C}\lVert \nabla H(y) \rVert.
\]
By the optimality conditions, we know that $y_\lambda = \frac{1}{\lambda}(A\Bar{x}-b)$ and so 
\[
\lVert y_\lambda \rVert \leq \frac{\lVert A \rVert + \lVert b \rVert}{\lambda} 
\]
since $\Bar{x} \in \Delta_n \subset B_1(0)$. Namely, it suffices to minimize over the $l_2$-ball of radius $\frac{\lVert A \rVert + \lVert b \rVert}{\lambda}$ for the dual problem \eqref{eq:dual} parameterized by $\lambda$. Assuming $\lambda' < \lambda$, we can then directly compare $\min_{C}F_\lambda(y)$ and  $\min_{C}F_{\lambda'}(y)$ where $C$ is the closed $l_2$-ball of radius $\frac{\lVert A \rVert + \lVert b \rVert}{\lambda'}$. Now, for the Lipschitz constant of $H$ on $C$, we have
\[
\kappa = \frac{\lVert A \rVert + \lVert b \rVert}{\lambda'} | \lambda - \lambda' |.
\]
Putting things together, we get the --- not great --- bound 
\textcolor{red}{
\[
\lVert x_\lambda - x_{\lambda'}\lVert \leq \left(\frac{2\lVert A \rVert}{\lambda}\right) \left(\frac{\lVert A \rVert + \lVert b \rVert}{\lambda'}\right) | \lambda - \lambda' |.
\]
}
If we assume $y_\lambda^{\epsilon}$ is an $\epsilon$-optimal solution of the dual problem parameterized by $\lambda$, we get the bound
\[
\lVert y_\lambda - y_{\lambda'}\lVert \leq 2 \left(\frac{\lVert A \rVert + \lVert b \rVert}{\lambda'\lambda}\right) | \lambda - \lambda' | + \sqrt{\frac{2 \epsilon}{\lambda}}
\]
by \cite[Proposition 4.32]{Bonnans2000}.



\subsection{Simple application of the Implicit Function Theorem}

Consider the function $F: \rr^{m+1} \times \rr^m \to \rr^m$ given by
\[
F((b,\lambda), y) = \lambda y - b + A \nabla L(u)|_{u = A^Ty}.
\]
Namely, $F((b,\lambda), y$ is the Jacobian of the dual objective. For parameters $(\Bar{b}, \Bar{\lambda})$, let $\Bar{y}$ be such that $F((\Bar{b},\Bar{\lambda}), \Bar{y}) = 0$, i.e. $\Bar{y}$ is the minimizer of the dual objective function for the parametrization $(\Bar{b}, \Bar{\lambda})$. From previous computations, we have
\[
\nabla_y F((\Bar{b},\Bar{\lambda}), \Bar{y}) = \Bar{\lambda}I + A \Bar{S} A^T
\]
which is invertible for $\Bar{\lambda} > 0$. Therefore, by the Implicit Function Theorem, there exists neighbourhood $U \ni (\Bar{b}, \Bar{\lambda})$, $V \ni \Bar{y}$, and a unique map $f:U \to V$ such that
\[
F((b,\lambda), f((b,\lambda))) = 0
\]
for all $(b,\lambda) \in U$. Moreover, $f \in C^\infty$ since $F \in C^\infty$. In words, for other parameters $(b,\lambda)$ near $(\Bar{b}, \Bar{\lambda})$, the corresponding unique minimizer $y$, corresponding to the dual objective parameterized by $(b,\lambda)$, can be expressed as an infinitely differentiable function of $(b,\lambda)$. 

Moreover, the Implicit Function Theorem \cite[Theorem 1B.1]{DontRock} tells us that for $(b, \lambda) \in U$,
\begin{align*}
f'(b,\lambda) &= - \nabla_y F((b,\lambda), f(b,\lambda))^{-1} \nabla_{(b,\lambda)} F((b,\lambda),  f(b,\lambda)) \\
&= - (\lambda I + A S A^T)^{-1}[-I \; y].
\end{align*}

By the mean-value inequality, we give a local Lipshitz bound on the optimal solution parameterized by $b$ and $\lambda$ from the above Jacobian computation. We get
\[
\lVert x_b - x_{b'}\lVert  \leq \frac{\lVert A \rVert}{\lambda} \rVert b - b' \rVert
\]
for all $b, b' \in \rr^m$ and 
\[
\lVert x_\lambda - x_{\lambda'}\lVert \leq \left(\frac{\lVert A \rVert}{\lambda}\right) \left(\frac{\lVert A \rVert + \lVert b \rVert}{\lambda'}\right) | \lambda - \lambda' |
\] for all $\lambda$ in a neighbourhood of $\lambda'$ since 
\[
\lVert (\lambda I + ASA^T)^{-1} \rVert \leq \lambda^{-1}
\]
and \[ 
\lVert y_\lambda \rVert \leq \frac{\lVert A \rVert + \lVert b \rVert}{\lambda} 
\]
by the optimality conditions.

\textcolor{teal}{Letting $x(b,\lambda): \rr^{m+1} \to \rr^n$ be the optimal value map of the primal problem \eqref{eq:primal}, applying the optimality condition \eqref{eq:op2a}, we have
\begin{align*}
x'(b, \lambda) &= \nabla_{(b, \lambda)}  [\nabla L(u)|_{u = A^Ty(b, \lambda)}] \\
&= - S A^T (\lambda I + A S A^T)^{-1}[-I \; y].
\end{align*}
by the chain rule.}


\subsection{Firm non-expansiveness of the prox-operator}

If one wishes to simply examine the sensitivity of the solution to perturbations in $b$, then one can easily obtain bounds using the non-expansiveness of the proximal operator. This way, we are actually able to do better than by referencing the results of \cite{Bonnans2000} --- namely removing the factor of $2$. To see this, note that 
\begin{align*}
     y_b &:= \argmin_{y \in \rr^m} \left\{ \frac{\lambda}{2} \lVert y \rVert^2 - b^Ty +  \log \left(\sum_{i=1}^n \mu_i \exp(A_i^T y)\right) \right\} \\
     &= \argmin_{y \in \rr^m} \left\{ \frac{1}{2\lambda^{-1}} \lVert y - b/\lambda \rVert^2 - \frac{1}{2 \lambda}b^Tb +  \underbrace{\log \left(\sum_{i=1}^n \mu_i \exp(A_i^T y)\right)}_{f(y)} \right\} \\
     &= \argmin_{y \in \rr^m} \left\{ \frac{1}{2\lambda^{-1}} \lVert y - b/\lambda \rVert^2 +  \underbrace{\log \left(\sum_{i=1}^n \mu_i \exp(A_i^T y)\right)}_{f(y)} \right\} \\
     &=: (P_{\lambda^{-1}}f)(b/\lambda) =  (P_1 (\lambda^{-1}f))(b/\lambda).
\end{align*}
Since 
\[
\lVert P_1g(x) - P_1g(y) \rVert^2 \leq \langle x - y,  P_1g(x) - P_1g(y) \rangle
\]
for any proper, lsc, and convex function $g$, we have 
\[
\lVert y_b - y_{b'} \rVert  \leq \frac{1}{\lambda} \rVert b - b' \rVert.
\]
In particular,
\[
\lVert x_b - x_{b'} \rVert  \leq \frac{\lVert A \rVert}{\lambda} \rVert b - b' \rVert.
\]


\begin{remark}
    Directional differentiability of the proximal map as in  \cite[Corollary 8]{friedGoodHoh2021perspective} could (maybe...) be used to examine sensitivity to $\lambda$.
\end{remark}


% \subsection{Using coderivatives as in \cite{berk2023lasso}}

% \textcolor{blue}{To-do...}


\section{Comments on the A. Beck and M. Teboulle paper}

Here are some general comments regarding \cite{Beck2003MirrorDA} and its relation to our work.

\begin{itemize}
    \item The projected subgradient algorithm is a method used to solve the nonsmooth convex optimization problem 
    \[
    \min f(x) \; \text{s.t.} \; x \in X \subseteq \rr^n.
    \]
    Each iteration of the projected subgradient algorithm can be written as
    \[
    x^{k+1} \in \argmin_{x \in X} \left\{ \langle x, \nabla f(x^k) \rangle + \frac{1}{2 t_k}\lVert x - x^k \rVert^2 \right\}
    \]
    where $t_k>0$ is a stepsize. Replacing the Euclidean norm with a more general distance-like function $D$ to better reflect the geometry of $X$ brings one to the subgradient algorithm with nonlinear projections (SANP) whose iterates are
     \[
    x^{k+1} \in \argmin_{x \in X} \left\{ \langle x, \nabla f(x^k) \rangle + \frac{1}{t_k}D(x, x^k) \right\}.
    \]
    
    \item They show that the mirror descent algorithm (MDA) --- which is defined for a strongly convex and $C^1$ function\footnote{It is sufficent for $\psi$ to be $C^1$ on $\interior X$.} $\psi: X \to \rr$ --- can be viewed as the SANP when $B_\psi(x,y) := \psi(x) - \psi(y) - \langle x-y, \nabla \psi(y) \rangle$ is used as the pseudo-distance in the SANP. In fact, \cite[Proposition 3.2]{Beck2003MirrorDA} shows that the algorithms generate the same iterates.
    
    \item In \cite[\S{5}]{Beck2003MirrorDA}, the authors propose an ``Entropic" MDA --- taking $\psi = -S(x)$\footnote{$S(x):= - \sum_{i=1}^n x_i \ln x_i$ if $x \in \Delta_n$ and $\infty$ otherwise is the Shannon entropy.} --- to minimize a nonsmooth convex function $f$ over $\Delta_n$. For us, this nonsmooth convex function can be taken to be 
    \begin{equation}\label{eq:objfunc_MDA}
    f(x) = \frac{1}{2 \lambda} \lVert Ax - b \rVert^2 + g_\mu(x).
    \end{equation}
    In which case, minimizing over $\Delta_n$ recovers the problem \eqref{eq:primal}. However, in their work $f: \Delta_n \to \rr$ must be Lipschitz on $\Delta_n$ (we can even work with $\rint \Delta_n)$ which does not fit our setting as $\lVert \nabla g_\mu(x) \rVert$ is unbounded on $\rint \Delta_n$. Therefore, if we wish to draw a connection between their work and ours, we cannot use the objective function in \eqref{eq:objfunc_MDA} which is of course the natural choice to fit their framework.

    \item In an attempt to apply the methods in \cite{Beck2003MirrorDA} to our setting and circumvent the issues pointed out in the above bullet, we may instead consider
    \begin{equation}\label{eq:objfunc_MDA_2}
    f(x) = \frac{1}{2 \lambda} \lVert Ax - b \rVert^2,
    \end{equation}
    which is indeed Lipschitz on $\Delta_n$, and take $\psi(x) = \KL(x|\mu)$ as defined at the beginning of this document.
\end{itemize}

\begin{remark}
    \textcolor{teal}{Nick: In \cite{Beck2003MirrorDA}, their results assume $X$ to have nonempty interior, but then apply these results to $X = \Delta_n$ and obviously $\interior \Delta_n = \emptyset$. Am I missing something here?}
\end{remark}

\section{Questions from Michael}

\subsection{Multiplier for the sum-to-one constraint}

\subsubsection{Optimality conditions for $e^T\Bar{x} = \tau$}

Generalizing to problem where $e^T\Bar{x} = \tau$ for $\tau >0$, consider 

\begin{equation}\label{eq:primal_tau}
    \min_{x \in \rr^n} \left\{ \frac{\lambda}{2} \lVert z \rVert^2 +  g_\mu(x) + \delta_{\tau}(e^Tx) : Ax + \lambda z = b \right\}.
\end{equation}
Observe that
\[
g_\mu(x) + \delta_{\tau}(e^Tx) = \tau [g_{\tau^{-1}\mu}(x/\tau) + \delta_{1}(e^Tx/\tau)] = \tau \KL(x/\tau | \underbrace{\tau^{-1} \mu}_{\nu})
\]
and 
\[
(\tau \KL(x/\tau | \nu) )^\ast = (\tau L_{\nu}(x))^{\ast \ast} = \tau L_{\nu}(x)
\]
where $L$ is the cumulant-generating function from Lemma \ref{lem:KL_dual}.

\begin{remark}
   Lemma \ref{lem:KL_dual} can easily be generalized for any $\nu \in \rr^n_{+}$ not necessarily in $\Delta_n$ by observing that $\tau \vecmax(\cdot)$ is the support function of $\tau \Delta_n$ $(\tau>0)$ and noting other trivial adaptations.
\end{remark}
The optimality conditions then read
\begin{align}
A\Bar{x} &+ \lambda \Bar{y} - b = 0 \label{eq:tau_op1}\\
\Bar{x}_j &= \nabla [\tau L_{\nu}(A^T\Bar{y})]_j = \frac{ \tau \mu_j \exp(A_j^T\Bar{y})}{\sum_{l=1}^n \mu_l \exp(A_l^T\Bar{y})} \qquad j \in \{1, \dots n\}. \label{eq:tau_op2}
\end{align}


\subsubsection{Alternative optimality conditions}

Keeping the first optimality condition \eqref{eq:op1}, we can replace \eqref{eq:op2a}  with 
\[
A^T\Bar{y} \in \partial [g_{\mu}(\Bar{x}) + \delta_{\{\tau\}}(e^T\Bar{x})] = \nabla g_{\mu}(\Bar{x}) + \rr e
\]
where one has the above equality from the sum rule for subdifferential calculus. Computing, we have the optimality condition 
\[
A^T\Bar{y} = \begin{bmatrix}
                \log \frac{\Bar{x}_1}{\mu_1} + 1 \\
                \vdots \\
                 \log \frac{\Bar{x}_n}{\mu_n} + 1
            \end{bmatrix} + \rho e
\]
for some $\rho \in \rr$.


\subsection{Spectrum of the preconditioned matrix}

We consider $M := (AA^T)^{-1}$\footnote{Assuming $A$ is full row rank ($ker A^T = \{0\}$).} as a preconditoner candidate for the matrix $ASA^T$ where $x \in \rint \Delta_n$. Writing the SVD decomposition $A = U \Sigma V^T$, we have
\[
M^{1/2} = U D^{-1/2}U^T 
\]
where $D = \diag(\sigma_1^2, \dots, \sigma_m^2)$ and thus 
\[
M^{1/2} ASA^T M^{1/2} = U\Bar{V}^T S \Bar{V}U^T
\]
where $\Bar{V} := [v_1 \cdots v_m] \in \rr^{n \times m}$. Hence, $MASA^T$ shares the same eigenvalues as $\Bar{V}^T S \Bar{V}$.

Since ${V}^T S \Bar{V}$ is symmetric,
\[
\lambda_{\max}(MASA^T) = \max_{\lVert z \rVert = 1}z^T \Bar{V}^T S \Bar{V} z \leq  \max_{\lVert y \rVert = 1}y^T S y \leq 1
\]
where in the first inequality we used that $\lVert \Bar{V} x \rVert \leq \lVert \Bar{V} \rVert \lVert x \rVert \leq \lVert V \rVert \lVert x \rVert = \lVert x \rVert$ and in the second inequality one simply looks at the definition of $S$.
Okay 
\subsection{Linear objective term}

Adding a linear term to the primal \eqref{eq:primal} and \eqref{eq:primal0}, we have the problem 
\begin{equation}\label{eq:linear_objective}
    \min_{x \in \rr^n} \left\{ \frac{\lambda}{2} \lVert z \rVert^2 + c^Tx + \KL(x| \mu) : Ax + \lambda z = b \right\}.
\end{equation}
This is equivalent to \eqref{eq:primal} and \eqref{eq:primal0} where one takes the prior to have entries $\mu_j \exp{(-c_j)}$ for $j=1,\dots,n$. Viewed another way, \eqref{eq:linear_objective} is 
\begin{equation}\label{eq:linear_objective_entropy}
     \min_{x \in \rr^n} \left\{ \frac{\lambda}{2} \lVert z \rVert^2 + d^Tx - S(x) : Ax + \lambda z = b \right\}
\end{equation}
where $d_j = c_j - \ln \mu_j$ for $j=1.\dots,n$. Looking to compute the dual of \eqref{eq:linear_objective} (equivalently \eqref{eq:linear_objective_entropy}), let $f(x) :=  c^Tx + \KL(x| \mu)$. We compute
\[
    f^\ast(x) = \sup_{u} \{ x^Tu - c^Tu - \KL(u| \mu) \} = \KL^\ast(x-c| \mu).
\]
Hence, the dual problem is 
\begin{equation}\label{eq:linear_dual}
    \min_{y \in \rr^m} \frac{\lambda}{2} \lVert y \rVert^2 - b^Ty +  \log \left(\sum_{i=1}^n \mu_i \exp(A_i^T y - c_i)\right).
\end{equation}

\begin{remark}
    The expression \eqref{eq:linear_dual} remains valid if one substitutes $\KL(x|\mu)$ for $-S(x)$ in the primal (see \cite[Example 11.12]{RockWets98}). In this setting, one simply has $\mu = e$ in \eqref{eq:linear_dual}.
\end{remark}

% \subsection{The dual with no simplex constraint}

% Consider the problem

% \[
%    \min_{(x, t) \in \rr^n \times \rr_{++}} \frac{1}{2 \lambda} \lVert Ax - b \rVert^2 + \underbrace{g_\mu(x) + \delta^\pi_{\Delta_n}(x,t)}_{g(x,t)}.
% \]

   \subsection{Comments on the Laplace Transform paper}

    In \cite{LaplaceInv}, the authors seek to recover a probability density function $f(t)$ of a non negative random variable having access to the Laplace Transform $f^\ast(s)$ of $f$ at certain values of $s$ in addition to having knowledge of the $k^{\text{th}}$ moments of $f(t)$ for $k=1, \dots, K$. That is, one observes 
    \begin{equation}\label{eq:moments}
    \int_0^\infty f(t) t^k \,dt = a_k \qquad (k=0,\dots, K)
     \end{equation}
    and 
     \begin{equation}\label{eq:laplace_values}
    \int_0^\infty f(t) e^{-s_i t} \,dt = f^\ast(s_i) \qquad (i=1,\dots, I),
    \end{equation}
    and wishes to extract a function $\hat{f}(t)$ satisfying the above two sets of constraints and be a probability density function, i.e.
    \[
    \hat{f} \geq 0, \qquad  \int_0^\infty \hat{f}(t) \,dt = 1.
    \]
    To recover $f(t)$, the authors give an optimization problem:
    \begin{equation}\label{eq:laplace_ent_opt}
        \max  - \int_0^\infty \hat{f}(t) \log \hat{f}(t) \,dt 
    \end{equation}
    such that $\hat{f}$ satisfies the constraints of \eqref{eq:moments} and \eqref{eq:laplace_values} -- namely maximizing the entropy of the recovered function. This will enforce $\hat{f} \geq 0$ as $-  \hat{f}(t) \log \hat{f}(t) = - \infty$ for $\hat{f}(t) < 0$. Moreover, though not stated in the paper, $a_0 = 1$ will ensure the solution be a probability density. To solve \eqref{eq:laplace_ent_opt}, they insert the functional form 
    \[
    \hat{f}(t) = \exp{(-1 - \sum_{k=0}^K\alpha_k t^k - \sum_{i=1}^I \beta_i e^{-s_i t})}
    \]
    (obtained from the Lagrangian) into \eqref{eq:moments} and \eqref{eq:laplace_values} and use an of-the-shelf FORTRAN program for solving nonlinear equations called C05PCF from the NAG-library. They do not elaborate on the details of the algorithms. 
    

\section{Generalization to matrix space}

Let $f: \mathbb{S}_n \to \rr \cup \{ \infty \}$ be the negative of the Von Neumann entropy. Namely,
\[
f(X) := \begin{cases}
			\tr(X \log X), & X \in \Sym _n^+ \text{ and } \tr(X) = 1 \\
            + \infty, & \text{else}.
		 \end{cases}
\]
Let $\cA: \mathbb{S}_n \to \rr^m$ be a linear operator. Note that 
we can write
\[
\cA(X) = \begin{bmatrix}
    \tr(A_1 X) \\
    \vdots \\
    \tr(A_m X) \\
\end{bmatrix}
\]
for some matrices $A_1, \dots, A_m \in \rr^{n \times n}$ \cite[\S{1.10}]{firstorderBeck}. Going forward we assume that $A_1, \dots, A_m \in \rr^{n \times n}$ are symmetric and share the same eigenvectors. Consider now the more general primal problem 
\begin{equation}\label{eq:primal:matrix}
 \min_{X \in \Sym_n} \frac{1}{2 \lambda} \lVert \cA(X) - b \rVert^2 + f(X).
\end{equation}
From \cite[Example 7.16]{firstorderBeck}, we see that 
\[
f^\ast(X) = \log \left(\sum_{i=1}^n \exp(\lambda_i(X))\right)
\]
with 
$\dom f^\ast = \Sym_n$\footnote{Assuming $A_j$'s are symmetric ensures $\cA^\ast(y)$ is symmetric and thus simplifying subsequent derivative computations. \textcolor{red}{Nick: Maybe symmetric is implied and need not be an assumption on the $A_j$'s?}}. By \cite[Corollary 5.2.3]{NonLin_COnvOpt}, $f$ is a proper, closed, and convex function. Moreover,
\[
\cA^\ast(y) = \sum_{i=1}^m y_i A_i
\]
(see \cite[\S{1.10}]{firstorderBeck}). We then obtain the dual problem
\begin{equation}\label{eq:dual:matrix}
    \min_{y \in \rr^m} \frac{\lambda}{2} \lVert y \rVert^2 - b^Ty +  \log \left(\sum_{i=1}^n \exp(\lambda_i(\cA^\ast(y)))\right).
\end{equation}
Writing the spectral decomposition of each $A_j$ as $A_j := U \Lambda_j U^T$ with $\Lambda_j = \diag(\lambda_j^1, \dots, \lambda_j^n)$ for $j=1, \dots, m$, we have
\[
\cA^\ast(y) = \sum_{j=1}^m y_j U \Lambda_j U_j^T = U \left( \sum_{j=1}^m y_j \Lambda_j \right) U_j^T.
\]
Hence, \begin{equation}\label{eq:eigvals_A*y}
[\lambda(\cA^\ast(y)]_i = \sum_{j=1}^m y_j \lambda_j^i
\end{equation}
for $i = 1, \dots, n$ and we note that the eigenvectors of $y$ depend on $\cA$ only. Writing $f = g \circ \lambda$ where $g(z) = \logsumexp(z)$, by \cite[Corollary 5.2.5]{NonLin_COnvOpt}, 
\[
\nabla f(X) = V \diag \nabla g(\lambda(X))V^T
\]
where $X = V \diag \lambda(X) V^T$ and one easily computes $\nabla g(z) = \softmax(z)$. We can now write the Fenchel--Rockafellar optimality conditions for \ref{eq:primal:matrix} and \ref{eq:dual:matrix} as 


\begin{align}
    \cA (\Bar{X}) &+ \lambda \Bar{y} - b = 0 \label{eq:op1_matrix}\\
    \Bar{X} &= U \diag \softmax(\lambda(\cA^\ast(\Bar{y}))) U^T. \label{eq:op2_matrix}
\end{align}

Letting $d(y)$ be the objective function of the dual $\eqref{eq:dual:matrix}$, a simple application of the chain rule to $f(\cA^\ast(y))$ yields
\[
\nabla d(y) = \lambda y - b + \cA \circ U \diag \softmax(\lambda(\cA^\ast(\Bar{y}))) U^T 
\]
To compute the $\nabla^2 d(y)$, let $P(y) = \cA \circ U \diag \softmax(\lambda(\cA^\ast(\Bar{y}))) U^T$ and let $P_j : \rr^m \to \rr$ be the $j^{\text{th}}$ component function of $P$ $(j=1, \dots, m)$.

\begin{proposition}
    Let $M \in \rr^{m \times n}$ be defined entry-wise by $M_{j,i} = \lambda_j^i$ (the $i^\text{th}$ eigenvalue of $A_j$). Namely,
    \[
    M = \begin{bmatrix}
        \lambda(A_1)^T \\
        \vdots \\
        \lambda(A_m)^T
    \end{bmatrix}
    \]
    Then, 
    \[
    \nabla^2 d(y) = \lambda I + M \nabla_u \softmax(u) M^T |_{u = M^Ty}.
    \]
\end{proposition}

\begin{proof}
We have,
\begin{align*}
P_j(y) &= \tr \left(A_j  U \diag \softmax[\lambda(\cA^\ast(y))] U^T \right) \\
 &= \tr \left(U \Lambda_j U^T  U \diag \softmax[\lambda(\cA^\ast(y))] U^T \right) \\
&= \tr(\Lambda_j  \diag \softmax[\lambda(\cA^\ast(y))]) \\
&= \lambda(A_j)^T \softmax(\lambda(\cA^\ast(y))).
\end{align*}
Inspecting \eqref{eq:eigvals_A*y}, we notice that 
\[
\lambda(\cA^\ast(y)) = M^Ty
\]
and so
\[
P_j(y) =  \lambda(A_j)^T \softmax(M^Ty).
\]
Viewed as a row-vector, we derive $\nabla P_j(y)$ by the chain-rule to be 
\[
\nabla P_j(y) =   \lambda(A_j)^T \nabla_u \softmax(u) M^T |_{u = M^Ty}.
\]
Hence, 
\[
\nabla P(y) = M \nabla_u \softmax(u) M^T |_{u = M^Ty}
\]
and so 
 \[
    \nabla^2 d(y) = \lambda I + M \nabla_u \softmax(u) M^T |_{u = M^Ty}.
    \]
\end{proof}

\begin{remark}
    If we do not assume that the $A_j$'s have the same eigenvectors then the above computations complicate fairly quickly. These papers may be useful in this case: \hyperlink{https://people.orie.cornell.edu/aslewis/publications/01-twice.pdf}{Twice Differentiable Spectral Functions} and \hyperlink{https://sites.math.washington.edu/~ddrusv/quick_spec.pdf}{Variational analysis of spectral functions simplified}. They give a general formula for computating the Hessian of symmetric spectral functions.
\end{remark}

\begin{remark}
    If $A_j = \diag(a_j)$ where $a_j \in \rr^n$ for $j =1, \dots, m$, then
    \[
    M = \begin{bmatrix}
         - a_1^T -  \\
        \vdots \\
        - a_m^T -
    \end{bmatrix}.
    \]
    Thus, we can think of $M$ simply as the matrix $A \in \rr^{m \times n}$ taken throughout this document. Notably, we retrieve the primal and dual problems of \eqref{eq:primal} and \eqref{eq:dual}. \textcolor{red}{This needs to be justified more rigorously, but the argument is simply that the vector space of trace 1 positive semi-definite diagonal matrices in $\rr^{n \times n}$ is isomorphic to $\Delta_n$.}
\end{remark}

\textbf{\textcolor{red}{Nick: after writing the below remark, I've learned that the $\KL$-divergence analog for matrices is known as Quantum relative entropy.}}
\begin{remark}
    What is the correct notion of the Kullback--Leibler divergence over the space $\Sym_n$? Let $Q \in \Sym_n^{++}$ satisfy $\tr(Q)=1$. Recalling the definitions of entropy, cross entropy, and relative entropy on $\rr^n$:
    \[
    S(p) := - \sum_i p_i \log p_i,
    \]
    \[
    S_c(p,q) := - \sum_i p_i \log q_i,
    \]
    and 
    \[
    \KL(p|q) = S_r(p,q) := S_c(p,q) - S(p) = \sum_i p_i \log \frac{p_i}{q_i},
    \]
    it is perhaps natural to define 
    \[
    \KL(P|Q) := \tr(P \log Q) - \tr(P \log Q) = \tr(P (\log P - \log Q))
    \]
    for $P \in \Sym_n^+$ with $\tr(P) = 1$. If we make the assumption that $P$ and $Q$ commute (and hence that they share the same eigenvectors), then the above definition is equivalent to 
    \[
     \KL(P|Q) =  \tr(P \log [P Q^{-1}] ) = \sum_i \lambda(P)_i \log \frac{\lambda(P)_i}{\lambda(Q)_i}.
    \]
    which is familiar to the well-known definition of the $\KL$-divergence considered throughout these notes. 
    
    \end{remark}







\section{Applications}

\subsection{Extracting a prior from data}

Consider the infinite-dimensional optimization problem
\begin{equation}\label{eq:inf_dim_primal}
 \min_{\rho \in \mathcal{P}(\rr^d)} \frac{1}{2 \lambda} \lVert A\ee_\rho - b \rVert^2 + \KL(\rho| \mu)
\end{equation}
where $A \in \rr^{m \times d}$, $\mathcal{P}(\rr^d)$ is the space of probability measures on $\rr^d$, $\ee_\rho$ is the expectation of $\rho$\footnote{It is perhaps easier to think of $\rho$ as the law of a random variable $X$ on $\rr^d$ in which case $\ee_\rho := \ee X$.}, and $\KL(\rho | \mu)$ is the usual Kullback--Leibler divergence defined between probability measures in terms of the Radon--Nikoodym derivative --- namely,
\[
\KL(\rho | \mu) = \int_{\rr^d} \log \frac{\dd \rho}{ \dd \mu} \dd \rho. \footnote{One should not readily assume that $\rho$ and $\mu$ are absolutely continuous w.r.t the Lebesgue measure on $\rr^d$ (as this will never be the case when $\mu$ is the empirical measure constructed from a finite collection of data) and so we avoid writing $\KL(\rho | \mu)$ in terms of densities.}
\]
See \cite{rioux2020maximum, vaisbourd2022} for a thorough development on \eqref{eq:inf_dim_primal}. To link the infinite-dimensional problem in \eqref{eq:inf_dim_primal} to the finite-dimensional framework of minimizing over $\Delta_n$, consider the scenario in which $\mu$ is the empirical measure constructed from i.i.d. samples $x^1, \dots, x^n \in \rr^d$\footnote{By i.i.d. samples, we mean that $x^1, \dots, x^n$ are realizations of a sequence of i.i.d. $\rr^d$-valued random variables $X_1, \dots, X_n \sim X $. Thus, $\mu$ is in fact a random measure which is equal to $\mathcal{L}_{X}$ in expectation and which converges to $\mathcal{L}_{X}$ by the Gilvenko-Cantelli Theorem as $n \to \infty$.}, namely 
\[
\mu(A):= \frac{|\{i: x^i \in A \}|}{n} = \frac{1}{n} \sum_{i=1}^n \mathbf{1}_A{(x_i)}
\]
for any Borel set $A$ on $\rr^d$. Let $1 \leq n' \leq n$ be the number of unique realizations which we denote by $\Tilde{x}^1, \dots, \Tilde{x}^{n'}$.  Now, since $\KL(\rho |\mu) < \infty$ only if $\rho \ll \mu$ and $\mu(\{\Tilde{x}^1, \dots, \Tilde{x}^{n'}\}^c) = 0$, it follows that any minimizer $\rho$ of \eqref{eq:inf_dim_primal} has $\supp \rho \subseteq \{\Tilde{x}^1, \dots, \Tilde{x}^{n'} \}$. Although a probability measure on $\rr^d$, $\mu$ can be encoded as a probability \emph{vector} in $\rr^{n'}$ where 
\[
\mu_j := \mu(\Tilde{x}^j) = \frac{|\{i: x^i = \Tilde{x}^j\}|}{n}.
\]
In particular, $\mu_j$ is the relative frequency of the realization $x^j$ out of all the sampled realizations $x^1, \dots, x^n$. Hence, if all our realizations are unique (i.e. $n = n')$, we simply have $\mu = \frac{1}{n} e \in \Delta_n$. Otherwise, $\mu \in \Delta_{n'}$. Similarly, for $\rho \in \mathcal{P}(\rr^d)$ --- restricting ourselves to $\rho \ll \mu$, we can encode $\rho$ as a probability \emph{vector} on $\rr^{n'}$ where we interpret
\[
\rho_j = \rho(\{x^j\}).
\]
Now, having encoded probability measures $\mu$ and $\rho$ on $\rr^d$ as probability vectors in $\rr^{n'}$ which was possible as $\mu$ had a discrete support, we are able to fit the infinite-dimensional problem of \eqref{eq:inf_dim_primal} into a finite-dimensional problem by noticing that for any $\rho \in \mathcal{P}(\rr^d)$ under consideration, we have 
\[
\KL(\rho|\mu) = \begin{cases}
			\sum_{i=1}^m \rho_i \log\frac{\rho_i}{\mu_i}, & \rho \in \Delta_{n'} \\
            + \infty, & \text{else}
		 \end{cases}
\]
\[
\ee_\rho = \sum_{i=1}^{n'} \Tilde{x}^i \rho_i = X \rho
\]
where $X = [\Tilde{x}^1 \dots \Tilde{x}^{n'}]$. That is, \eqref{eq:inf_dim_primal} is equivalent to 
\[
 \min_{\rho \in \Delta_{n'}} \frac{1}{2 \lambda} \lVert \Tilde{A}\rho - b \rVert^2 + \KL(\rho| \mu)
\]
where $\Tilde{A} = A X \in \rr^{m \times n'}$.

\subsection{Adapting to the physics application}

In the physics applications of Tobias and TC, the vector $\Bar{x}$ representing a ``spectral density" that we wish to recover is positive yet may not be in the unit simplex. As a result, given that the observed measurements $b$ were derived from the unnormalized vector $\Bar{x}$, it is not productive or meaningful to apply \eqref{eq:primal} or \eqref{eq:primal0} in hopes to recover it. This being said, knowing $x^Te$ and assuming that the provided prior $\mu$ satisfies $\mu^Te = x^Te$, we can transform the data so that the problems \eqref{eq:primal} and \eqref{eq:primal0} can be applied while staying true to the intuition of the KL divergence. 

In the setting of Tobias' application, one has $e^Tx = b_1$\footnote{\textcolor{teal}{So in the data we should expect $a_{1j}=1$ for all $j=1,\dots,n$? Otherwise, they must be leveraging some structure in $x$ that would be useful.}} and $e^Tx = e^T\mu$ save for some \emph{small} numerical precision for which we omit mentioning at the moment. \footnote{\textcolor{blue}{Since $e^Tx$ and $e^T\mu$ may differ, perhaps it is useful to say which should take precedent as a normalizing factor in applications...}} In this light, let us define 
\[
\Tilde{b} := b/b_1
\quad\text{and}\quad
\Tilde{\mu} := \mu/b_1,
\]
and solve \eqref{eq:primal} and \eqref{eq:primal0} where $b$ and $\mu$ have been replaced by $\Tilde{b}$ and $\Tilde{\mu}$ respectively. Then, focusing on \eqref{eq:primal0}, we see that $\Tilde{x}:= \Bar{x}/b_1 \in \Delta_n$ is a solution to $Ax = \Tilde{b}$ by linearity and the evaluation $KL(\Tilde{x}|\Tilde{\mu})$ provides a meaningful interpretation of the ``distance" between two discrete probability measures. Having obtained this solution $\Tilde{x}$, we simply return $b_1 \Bar{x}$ as the desired solution to the practitioner. 

\begin{remark}
    In applying the above strategy to the least-squares variant \eqref{eq:primal}, one should note that an $\epsilon$-close residual $\lVert A\Tilde{x}- \Tilde{b} \rVert = \epsilon$ in the modified-data scheme will yield $\lVert A\bar{x}- b \rVert = b_1 \epsilon$.
\end{remark}

\bibliographystyle{amsalpha}
\bibliography{refs,maxent} 

\end{document}