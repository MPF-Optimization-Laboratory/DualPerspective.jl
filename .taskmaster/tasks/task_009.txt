# Task ID: 9
# Title: Implement Gauss-Newton Solver
# Status: pending
# Dependencies: 5, 6
# Priority: medium
# Description: Develop a specialized Gauss-Newton solver for problems with nonlinear least-squares structure.
# Details:
Implement a Gauss-Newton solver specialized for problems with nonlinear least-squares structure. This solver approximates the Hessian using the Jacobian of the residual function, which is often more efficient and numerically stable.

```julia
function gauss_newton(model::DPModel, x0::AbstractVector; 
                    max_iter=100, 
                    tol=1e-6,
                    verbose=false)
    x = copy(x0)
    n = length(x)
    m = length(model.b)  # Number of constraints/residuals
    
    # Initialize
    iter = 0
    residual = model.A * x - model.b
    norm_r0 = norm(residual)
    norm_r = norm_r0
    
    while iter < max_iter && norm_r > tol * max(1.0, norm_r0)
        # Compute Jacobian of residual (A in this case)
        J = model.A
        
        # Compute gradient of objective
        g = J' * residual / model.λ
        
        # Add gradient of regularization term
        for i in 1:n
            if x[i] > 0
                g[i] += model.c[i] + log(x[i] / model.x̄[i]) + 1
            end
        end
        
        # Gauss-Newton approximation of Hessian: J'J/λ + diag(1/x)
        H_gn = J' * J / model.λ
        for i in 1:n
            if x[i] > 0
                H_gn[i,i] += 1.0 / x[i]
            else
                H_gn[i,i] += 1e10  # Large value for numerical stability
            end
        end
        
        # Solve Gauss-Newton system
        p = -H_gn \ g
        
        # Line search
        alpha = 1.0
        fx = obj(model, x)
        slope = dot(g, p)
        
        # Backtracking line search
        while alpha > 1e-10
            x_new = x + alpha * p
            # Project to ensure nonnegativity
            x_new .= max.(0.0, x_new)
            fx_new = obj(model, x_new)
            
            if fx_new <= fx + 1e-4 * alpha * slope
                x .= x_new
                break
            end
            alpha *= 0.5
        end
        
        # Update residual and check convergence
        residual = model.A * x - model.b
        norm_r = norm(residual)
        iter += 1
        
        if verbose
            println("Iteration $iter: obj = $(obj(model, x)), |r| = $norm_r, alpha = $alpha")
        end
    end
    
    return x, iter, norm_r
end
```

Implement a matrix-free version for large-scale problems:

```julia
function gauss_newton_matrixfree(model::DPModel, x0::AbstractVector; 
                               max_iter=100, 
                               tol=1e-6,
                               cg_tol=0.1,
                               cg_max_iter=20,
                               verbose=false)
    # Similar to gauss_newton but uses CG to solve the inner linear system
    # without explicitly forming the Gauss-Newton Hessian approximation
    # ...
    
    # Define a function for Gauss-Newton Hessian-vector product
    function gn_hessian_product(v)
        # J'(J*v)/λ + diag(1/x)*v
        Jv = model.A * v
        result = model.A' * Jv / model.λ
        
        for i in 1:n
            if x[i] > 0
                result[i] += v[i] / x[i]
            else
                result[i] += 1e10 * v[i]  # Large value for numerical stability
            end
        end
        
        return result
    end
    
    # Use this function in a CG solver for the Gauss-Newton system
    # ...
    
    return x, iter, norm_r
end
```

# Test Strategy:
Test the Gauss-Newton solver with:
1. Compare against Newton methods on least-squares problems
2. Verify convergence rates (should be quadratic for zero-residual problems)
3. Test with various problem sizes and condition numbers
4. Benchmark performance and iteration counts
5. Verify solution quality using KKT conditions
6. Test the matrix-free implementation against the explicit version
7. Verify handling of problems with non-zero residuals at the solution
